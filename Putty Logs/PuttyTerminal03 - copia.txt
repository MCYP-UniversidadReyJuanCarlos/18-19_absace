Using username "ubuntu".
Authenticating with public key "imported-openssh-key"
Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 5.3.0-1032-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Thu Aug 13 17:04:48 UTC 2020

  System load:                    1.33
  Usage of /:                     47.9% of 29.02GB
  Memory usage:                   1%
  Swap usage:                     0%
  Processes:                      132
  Users logged in:                1
  IP address for eth0:            172.31.41.31
  IP address for br-a66a8ffeed78: 172.20.0.1
  IP address for docker0:         172.17.0.1
  IP address for br-38232b45ac7d: 172.21.0.1
  IP address for br-3f052ecb7750: 172.18.0.1
  IP address for br-8433c55209a4: 172.19.0.1

 * Are you ready for Kubernetes 1.19? It's nearly here! Try RC3 with
   sudo snap install microk8s --channel=1.19/candidate --classic

   https://microk8s.io/ has docs and details.

 * Canonical Livepatch is available for installation.
   - Reduce system reboots and improve kernel security. Activate at:
     https://ubuntu.com/livepatch

13 packages can be updated.
0 updates are security updates.


Last login: Thu Aug 13 17:04:42 2020 from 95.125.241.104
ubuntu@ip-172-31-41-31:~$ cd 18-19_absace/
ubuntu@ip-172-31-41-31:~/18-19_absace$ docker-compose up
Pulling clair-scanner (nordri/clair-scanner:latest)...
latest: Pulling from nordri/clair-scanner
db0035920883: Already exists
b30a0dda1f07: Already exists
c28773f3b6fa: Already exists
Digest: sha256:652e9b9c57a9366787265ed901e52631239a513bc3869c04e313bc87f097e300
Status: Downloaded newer image for nordri/clair-scanner:latest
Starting 18-19_absace_clair-scanner_1 ... done
Starting 18-19_absace_sonarqube_1     ... done
Starting 18-19_absace_postgres_1      ... done
Starting 18-19_absace_jenkins_1       ... done
Starting 18-19_absace_clair_1         ... done
Starting 18-19_absace_clairctl_1      ... done
Attaching to 18-19_absace_clair-scanner_1, 18-19_absace_sonarqube_1, 18-19_absace_jenkins_1, 18-19_absace_postgres_1, 18-19_absace_clair_1, 18-19_absace_clairctl_1
clair_1          | {"Event":"running database migrations","Level":"info","Location":"pgsql.go:216","Time":"2020-08-13 17:07:12.198774"}
clair_1          | {"Event":"database migration ran successfully","Level":"info","Location":"pgsql.go:223","Time":"2020-08-13 17:07:12.254160"}
clair_1          | {"Event":"starting health API","Level":"info","Location":"api.go:85","Time":"2020-08-13 17:07:12.254504","port":6061}
clair_1          | {"Event":"starting main API","Level":"info","Location":"api.go:52","Time":"2020-08-13 17:07:12.255039","port":6060}
clair_1          | {"Event":"updater service started","Level":"info","Location":"updater.go:81","Time":"2020-08-13 17:07:12.254582","lock identifier":"5513701f-1d08-439c-8f75-f6f355f68f75"}
clair_1          | {"Event":"notifier service is disabled","Level":"info","Location":"notifier.go:77","Time":"2020-08-13 17:07:12.255762"}
clair_1          | {"Event":"updating vulnerabilities","Level":"info","Location":"updater.go:182","Time":"2020-08-13 17:07:12.270336"}
clair_1          | {"Event":"fetching vulnerability updates","Level":"info","Location":"updater.go:228","Time":"2020-08-13 17:07:12.270402"}
clair_1          | {"Event":"Start fetching vulnerabilities","Level":"info","Location":"oracle.go:119","Time":"2020-08-13 17:07:12.270462","package":"Oracle Linux"}
clair_1          | {"Event":"Start fetching vulnerabilities","Level":"info","Location":"alpine.go:52","Time":"2020-08-13 17:07:12.270684","package":"Alpine"}
clair_1          | {"Event":"Start fetching vulnerabilities","Level":"info","Location":"debian.go:63","Time":"2020-08-13 17:07:12.270749","package":"Debian"}
clair_1          | {"Event":"Start fetching vulnerabilities","Level":"info","Location":"ubuntu.go:85","Time":"2020-08-13 17:07:12.270780","package":"Ubuntu"}
clair_1          | {"Event":"Start fetching vulnerabilities","Level":"info","Location":"rhel.go:92","Time":"2020-08-13 17:07:12.270573","package":"RHEL"}
jenkins_1        | Running from: /usr/share/jenkins/jenkins.war
jenkins_1        | webroot: EnvVars.masterEnvVars.get("JENKINS_HOME")
18-19_absace_clair-scanner_1 exited with code 0
sonarqube_1      | 2020.08.13 12:40:20 WARN  es[][o.e.b.BootstrapChecks] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
sonarqube_1      | 2020.08.13 12:40:23 INFO  es[][o.e.c.s.MasterService] zen-disco-elected-as-master ([0] nodes joined), reason: new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{nCxBbZsvR16zhN9z2GGBCg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}
sonarqube_1      | 2020.08.13 12:40:23 INFO  es[][o.e.c.s.ClusterApplierService] new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{nCxBbZsvR16zhN9z2GGBCg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}, reason: apply cluster state (from master [master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{nCxBbZsvR16zhN9z2GGBCg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube} committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])
sonarqube_1      | 2020.08.13 12:40:23 INFO  es[][o.e.n.Node] started
sonarqube_1      | 2020.08.13 12:40:24 INFO  es[][o.e.g.GatewayService] recovered [7] indices into cluster_state
sonarqube_1      | 2020.08.13 12:40:26 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[components][4], [metadatas][0]] ...]).
sonarqube_1      | 2020.08.13 12:53:47 INFO  es[][o.e.n.Node] stopping ...
sonarqube_1      | 2020.08.13 12:53:47 INFO  es[][o.e.n.Node] stopped
sonarqube_1      | 2020.08.13 12:53:47 INFO  es[][o.e.n.Node] closing ...
sonarqube_1      | 2020.08.13 12:53:47 INFO  es[][o.e.n.Node] closed
jenkins_1        | 2020-08-13 17:07:11.602+0000 [id=1]  INFO    org.eclipse.jetty.util.log.Log#initialized: Logging initialized @794ms to org.eclipse.jetty.util.log.JavaUtilLog
jenkins_1        | 2020-08-13 17:07:11.857+0000 [id=1]  INFO    winstone.Logger#logInternal: Beginning extraction from war file
jenkins_1        | 2020-08-13 17:07:11.928+0000 [id=1]  WARNING o.e.j.s.handler.ContextHandler#setContextPath: Empty contextPath
jenkins_1        | 2020-08-13 17:07:12.014+0000 [id=1]  INFO    org.eclipse.jetty.server.Server#doStart: jetty-9.4.27.v20200227; built: 2020-02-27T18:37:21.340Z; git: a304fd9f351f337e7c0e2a7c28878dd536149c6c; jvm 1.8.0_242-b08
sonarqube_1      | 2020.08.13 17:07:11 INFO  app[][o.s.a.AppFileSystem] Cleaning or creating temp directory /opt/sonarqube/temp
sonarqube_1      | 2020.08.13 17:07:11 INFO  app[][o.s.a.es.EsSettings] Elasticsearch listening on /127.0.0.1:9001
sonarqube_1      | 2020.08.13 17:07:12 INFO  app[][o.s.a.ProcessLauncherImpl] Launch process[[key='es', ipcIndex=1, logFilenamePrefix=es]] from [/opt/sonarqube/elasticsearch]: /opt/sonarqube/elasticsearch/bin/elasticsearch
sonarqube_1      | 2020.08.13 17:07:12 INFO  app[][o.s.a.SchedulerImpl] Waiting for Elasticsearch to be up and running
postgres_1       |
postgres_1       | PostgreSQL Database directory appears to contain a database; Skipping initialization
postgres_1       |
postgres_1       | LOG:  database system was shut down at 2020-08-13 12:53:57 UTC
postgres_1       | LOG:  MultiXact member wraparound protections are now enabled
postgres_1       | LOG:  autovacuum launcher started
postgres_1       | LOG:  database system is ready to accept connections
sonarqube_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
clair_1          | {"Event":"finished fetching","Level":"info","Location":"updater.go:242","Time":"2020-08-13 17:07:12.728833","updater name":"rhel"}
jenkins_1        | 2020-08-13 17:07:12.781+0000 [id=1]  INFO    o.e.j.w.StandardDescriptorProcessor#visitServlet: NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
sonarqube_1      | 2020.08.13 17:07:12 INFO  app[][o.e.p.PluginsService] no modules loaded
sonarqube_1      | 2020.08.13 17:07:12 INFO  app[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
jenkins_1        | 2020-08-13 17:07:12.927+0000 [id=1]  INFO    o.e.j.s.s.DefaultSessionIdManager#doStart: DefaultSessionIdManager workerName=node0
jenkins_1        | 2020-08-13 17:07:12.928+0000 [id=1]  INFO    o.e.j.s.s.DefaultSessionIdManager#doStart: No SessionScavenger set, using defaults
jenkins_1        | 2020-08-13 17:07:12.934+0000 [id=1]  INFO    o.e.j.server.session.HouseKeeper#startScavenging: node0 Scavenging every 660000ms
clair_1          | {"Event":"finished fetching","Level":"info","Location":"updater.go:242","Time":"2020-08-13 17:07:13.054786","updater name":"oracle"}
clair_1          | {"Event":"finished fetching","Level":"info","Location":"updater.go:242","Time":"2020-08-13 17:07:13.510132","updater name":"alpine"}
clair_1          | {"Event":"Debian bullseye is not mapped to any version number (eg. Jessie-\u003e8). Please update me.","Level":"warning","Location":"debian.go:134","Time":"2020-08-13 17:07:13.611511"}
clair_1          | {"Event":"finished fetching","Level":"info","Location":"updater.go:242","Time":"2020-08-13 17:07:13.611602","updater name":"debian"}
jenkins_1        | 2020-08-13 17:07:13.680+0000 [id=1]  INFO    hudson.WebAppMain#contextInitialized: Jenkins home directory: /var/jenkins_home found at: EnvVars.masterEnvVars.get("JENKINS_HOME")
jenkins_1        | 2020-08-13 17:07:13.945+0000 [id=1]  INFO    o.e.j.s.handler.ContextHandler#doStart: Started w.@4470fbd6{Jenkins v2.235.3,/,file:///var/jenkins_home/war/,AVAILABLE}{/var/jenkins_home/war}
jenkins_1        | 2020-08-13 17:07:14.054+0000 [id=1]  INFO    o.e.j.server.AbstractConnector#doStart: Started ServerConnector@5315b42e{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}
jenkins_1        | 2020-08-13 17:07:14.054+0000 [id=1]  INFO    org.eclipse.jetty.server.Server#doStart: Started @3247ms
jenkins_1        | 2020-08-13 17:07:14.055+0000 [id=21] INFO    winstone.Logger#logInternal: Winstone Servlet Engine running: controlPort=disabled
jenkins_1        | 2020-08-13 17:07:15.683+0000 [id=27] INFO    jenkins.InitReactorRunner$1#onAttained: Started initialization
sonarqube_1      | 2020.08.13 17:07:15 INFO  es[][o.e.e.NodeEnvironment] using [1] data paths, mounts [[/opt/sonarqube/data (/dev/xvda1)]], net usable_space [15.1gb], net total_space [29gb], types [ext4]
sonarqube_1      | 2020.08.13 17:07:15 INFO  es[][o.e.e.NodeEnvironment] heap size [494.9mb], compressed ordinary object pointers [true]
sonarqube_1      | 2020.08.13 17:07:15 INFO  es[][o.e.n.Node] node name [sonarqube], node ID [OspwetY9T2i0OWqdt0vgOg]
sonarqube_1      | 2020.08.13 17:07:15 INFO  es[][o.e.n.Node] version[6.8.0], pid[31], build[default/tar/65b6179/2019-05-15T20:06:13.172855Z], OS[Linux/5.3.0-1032-aws/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/11.0.8/11.0.8+10]
sonarqube_1      | 2020.08.13 17:07:15 INFO  es[][o.e.n.Node] JVM arguments [-XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=/opt/sonarqube/temp, -XX:ErrorFile=../logs/es_hs_err_pid%p.log, -Xms512m, -Xmx512m, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/opt/sonarqube/elasticsearch, -Des.path.conf=/opt/sonarqube/temp/conf/es, -Des.distribution.flavor=default, -Des.distribution.type=tar]
sonarqube_1      | 2020.08.13 17:07:16 INFO  es[][o.e.p.PluginsService] loaded module [analysis-common]
sonarqube_1      | 2020.08.13 17:07:16 INFO  es[][o.e.p.PluginsService] loaded module [lang-painless]
sonarqube_1      | 2020.08.13 17:07:16 INFO  es[][o.e.p.PluginsService] loaded module [mapper-extras]
sonarqube_1      | 2020.08.13 17:07:16 INFO  es[][o.e.p.PluginsService] loaded module [parent-join]
sonarqube_1      | 2020.08.13 17:07:16 INFO  es[][o.e.p.PluginsService] loaded module [percolator]
sonarqube_1      | 2020.08.13 17:07:16 INFO  es[][o.e.p.PluginsService] loaded module [reindex]
sonarqube_1      | 2020.08.13 17:07:16 INFO  es[][o.e.p.PluginsService] loaded module [repository-url]
sonarqube_1      | 2020.08.13 17:07:16 INFO  es[][o.e.p.PluginsService] loaded module [transport-netty4]
sonarqube_1      | 2020.08.13 17:07:16 INFO  es[][o.e.p.PluginsService] no plugins loaded
jenkins_1        | 2020-08-13 17:07:16.861+0000 [id=32] INFO    jenkins.InitReactorRunner$1#onAttained: Listed all plugins
sonarqube_1      | 2020.08.13 17:07:19 WARN  es[][o.e.d.c.s.Settings] [http.enabled] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version.
sonarqube_1      | 2020.08.13 17:07:20 INFO  es[][o.e.d.DiscoveryModule] using discovery type [zen] and host providers [settings]
sonarqube_1      | 2020.08.13 17:07:20 INFO  es[][o.e.n.Node] initialized
sonarqube_1      | 2020.08.13 17:07:20 INFO  es[][o.e.n.Node] starting ...
sonarqube_1      | 2020.08.13 17:07:20 INFO  es[][o.e.t.TransportService] publish_address {127.0.0.1:9001}, bound_addresses {127.0.0.1:9001}
sonarqube_1      | 2020.08.13 17:07:20 WARN  es[][o.e.b.BootstrapChecks] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
sonarqube_1      | 2020.08.13 17:07:24 INFO  es[][o.e.c.s.MasterService] zen-disco-elected-as-master ([0] nodes joined), reason: new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{ndDrqE74RBKZJXprsVgWOg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}
sonarqube_1      | 2020.08.13 17:07:24 INFO  es[][o.e.c.s.ClusterApplierService] new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{ndDrqE74RBKZJXprsVgWOg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}, reason: apply cluster state (from master [master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{ndDrqE74RBKZJXprsVgWOg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube} committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])
sonarqube_1      | 2020.08.13 17:07:24 INFO  es[][o.e.n.Node] started
jenkins_1        | 2020-08-13 17:07:24.910+0000 [id=30] INFO    jenkins.InitReactorRunner$1#onAttained: Prepared all plugins
jenkins_1        | 2020-08-13 17:07:24.927+0000 [id=31] INFO    jenkins.InitReactorRunner$1#onAttained: Started all plugins
sonarqube_1      | 2020.08.13 17:07:24 INFO  es[][o.e.g.GatewayService] recovered [7] indices into cluster_state
sonarqube_1      | 2020.08.13 17:07:26 INFO  app[][o.s.a.SchedulerImpl] Process[es] is up
sonarqube_1      | 2020.08.13 17:07:26 INFO  app[][o.s.a.ProcessLauncherImpl] Launch process[[key='web', ipcIndex=2, logFilenamePrefix=web]] from [/opt/sonarqube]: /usr/local/openjdk-11/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/opt/sonarqube/temp --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.rmi/sun.rmi.transport=ALL-UNNAMED -Xmx512m -Xms128m -XX:+HeapDumpOnOutOfMemoryError -Djava.security.egd=file:/dev/./urandom -Dhttp.nonProxyHosts=localhost|127.*|[::1] -cp ./lib/common/*:/opt/sonarqube/lib/jdbc/h2/h2-1.3.176.jar org.sonar.server.app.WebServer /opt/sonarqube/temp/sq-process11108253139561838007properties
jenkins_1        | 2020-08-13 17:07:26.969+0000 [id=33] WARNING o.j.p.d.DockerBuilder$DescriptorImpl#<init>: Docker URL is not set, docker client won't be initialized
jenkins_1        | 2020-08-13 17:07:27.187+0000 [id=27] INFO    jenkins.InitReactorRunner$1#onAttained: Augmented all extensions
jenkins_1        | 2020-08-13 17:07:27.303+0000 [id=27] INFO    jenkins.InitReactorRunner$1#onAttained: System config loaded
jenkins_1        | 2020-08-13 17:07:27.304+0000 [id=33] INFO    jenkins.InitReactorRunner$1#onAttained: System config adapted
sonarqube_1      | 2020.08.13 17:07:27 INFO  web[][o.s.p.ProcessEntryPoint] Starting web
jenkins_1        | 2020-08-13 17:07:27.455+0000 [id=33] INFO    jenkins.InitReactorRunner$1#onAttained: Loaded all jobs
jenkins_1        | 2020-08-13 17:07:27.456+0000 [id=29] INFO    jenkins.InitReactorRunner$1#onAttained: Configuration for all jobs updated
sonarqube_1      | 2020.08.13 17:07:26 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[metadatas][0], [components][2], [components][1]] ...]).
jenkins_1        | 2020-08-13 17:07:27.589+0000 [id=46] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started Download metadata
jenkins_1        | 2020-08-13 17:07:27.596+0000 [id=46] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished Download metadata. 6 ms
jenkins_1        | 2020-08-13 17:07:28.037+0000 [id=32] INFO    o.s.c.s.AbstractApplicationContext#prepareRefresh: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@54b1033a: display name [Root WebApplicationContext]; startup date [Thu Aug 13 17:07:28 UTC 2020]; root of context hierarchy
jenkins_1        | 2020-08-13 17:07:28.038+0000 [id=32] INFO    o.s.c.s.AbstractApplicationContext#obtainFreshBeanFactory: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@54b1033a]: org.springframework.beans.factory.support.DefaultListableBeanFactory@40d19b37
jenkins_1        | 2020-08-13 17:07:28.049+0000 [id=32] INFO    o.s.b.f.s.DefaultListableBeanFactory#preInstantiateSingletons: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@40d19b37: defining beans [authenticationManager]; root of factory hierarchy
jenkins_1        | 2020-08-13 17:07:28.252+0000 [id=32] INFO    o.s.c.s.AbstractApplicationContext#prepareRefresh: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@187a32f: display name [Root WebApplicationContext]; startup date [Thu Aug 13 17:07:28 UTC 2020]; root of context hierarchy
jenkins_1        | 2020-08-13 17:07:28.252+0000 [id=32] INFO    o.s.c.s.AbstractApplicationContext#obtainFreshBeanFactory: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@187a32f]: org.springframework.beans.factory.support.DefaultListableBeanFactory@6b3f0a6
jenkins_1        | 2020-08-13 17:07:28.253+0000 [id=32] INFO    o.s.b.f.s.DefaultListableBeanFactory#preInstantiateSingletons: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@6b3f0a6: defining beans [filter,legacy]; root of factory hierarchy
jenkins_1        | 2020-08-13 17:07:28.317+0000 [id=32] INFO    jenkins.InitReactorRunner$1#onAttained: Completed initialization
sonarqube_1      | 2020.08.13 17:07:28 INFO  web[][o.a.t.u.n.NioSelectorPool] Using a shared selector for servlet write/read
jenkins_1        | 2020-08-13 17:07:28.493+0000 [id=20] INFO    hudson.WebAppMain$3#run: Jenkins is fully up and running
sonarqube_1      | 2020.08.13 17:07:29 INFO  web[][o.e.p.PluginsService] no modules loaded
sonarqube_1      | 2020.08.13 17:07:29 INFO  web[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.join.ParentJoinPlugin]
sonarqube_1      | 2020.08.13 17:07:29 INFO  web[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
sonarqube_1      | 2020.08.13 17:07:29 INFO  web[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
sonarqube_1      | 2020.08.13 17:07:30 INFO  web[][o.s.s.e.EsClientProvider] Connected to local Elasticsearch: [127.0.0.1:9001]
sonarqube_1      | 2020.08.13 17:07:30 INFO  web[][o.s.s.p.LogServerVersion] SonarQube Server / 7.9.4.35981 / 0a370ee33e97c5d5e3a038a3f7dc4c0162319835
sonarqube_1      | 2020.08.13 17:07:30 INFO  web[][o.s.s.p.d.EmbeddedDatabase] Starting embedded database on port 9092 with url jdbc:h2:tcp://127.0.0.1:9092/sonar
sonarqube_1      | 2020.08.13 17:07:30 INFO  web[][o.s.s.p.d.EmbeddedDatabase] Embedded database started. Data stored in: /opt/sonarqube/data
sonarqube_1      | 2020.08.13 17:07:30 INFO  web[][o.sonar.db.Database] Create JDBC data source for jdbc:h2:tcp://127.0.0.1:9092/sonar
sonarqube_1      | 2020.08.13 17:07:31 WARN  web[][o.s.db.dialect.H2] H2 database should be used for evaluation purpose only.
sonarqube_1      | 2020.08.13 17:07:31 INFO  web[][o.s.s.p.ServerFileSystemImpl] SonarQube home: /opt/sonarqube
sonarqube_1      | 2020.08.13 17:07:31 INFO  web[][o.s.s.u.SystemPasscodeImpl] System authentication by passcode is disabled
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin Git / 1.8.0.1574 / aec3dc8f5228aabd218e1cd31ac6e6515a43715d
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin GitHub Authentication for SonarQube / 1.5.0.870 / 153f7c7af7a264adb0fcbe5fee87bdd140a6a3a1
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin JaCoCo / 1.0.2.475 / b79a4724f3a9af1051266b4f8ca0460977295ead
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin LDAP / 2.2.0.608 / 79dc3fa4393a29667673c70182f3016288b548b7
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SAML 2.0 Authentication for SonarQube / 1.2.0.682 / 44d64e660a3c7f235962a7bcfef78bf8c87db98a
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarC# / 7.15.0.8572 / e0ad49e38a28a8fc333ba746fc998e48678f6a8b
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarCSS / 1.1.1.1010 / 365e21fd0cb9035669fc59f6fec7c8fd28a7303b
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarFlex / 2.5.1.1831 / a0c44437f6abb0feec76edd073f91fec64db2a6c
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarGo / 1.1.1.2000 / 40d55921c7a63b67386a053490d17b6723a46cd5
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarHTML / 3.1.0.1615 / 4181edb5eff5605bec82dc0aa15ecd70eaa5857f
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarJS / 5.2.1.7778 / 49f34eaeaad59868d4353d89b1fc5c02bbe51976
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarJava / 5.13.1.18282 / 568f8ed2349f48e250a9329895b9a870100dfbeb
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarKotlin / 1.5.0.315 / 4ff3a145a58f3f84f1b39846a205a129d742e993
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarPHP / 3.2.0.4868 / ec66bd5f8490677eb0ebae82aa17c2a5d9c0e5e7
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarPython / 1.14.1.3143 / eed7b315b6116fe462a19c771013bf3891c92a97
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarRuby / 1.5.0.315 / 4ff3a145a58f3f84f1b39846a205a129d742e993
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarScala / 1.5.0.315 / 4ff3a145a58f3f84f1b39846a205a129d742e993
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarTS / 1.9.0.3766 / 4a4080b78001a78d758d1d0fa0190fb9496b6f57
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarVB / 7.15.0.8572 / e0ad49e38a28a8fc333ba746fc998e48678f6a8b
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarXML / 2.0.1.2020 / c5b84004face582d56f110e24c29bf9c6a679e69
sonarqube_1      | 2020.08.13 17:07:32 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin Svn / 1.9.0.1295 / 942e075773975354e32691a60bfd968065703e04
sonarqube_1      | 2020.08.13 17:07:33 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.WebServiceFilter@70228495 [pattern=UrlPattern{inclusions=[/api/system/migrate_db.*, ...], exclusions=[/api/properties*, ...]}]
sonarqube_1      | 2020.08.13 17:07:33 INFO  web[][o.s.s.a.EmbeddedTomcat] HTTP connector enabled on port 9000
sonarqube_1      | 2020.08.13 17:07:34 INFO  web[][o.s.s.p.UpdateCenterClient] Update center: https://update.sonarsource.org/update-center.properties (no proxy)
sonarqube_1      | 2020.08.13 17:07:35 INFO  web[][o.s.s.s.LogServerId] Server ID: BF41A1F2-AXOwq_Q3V0p2MHt8HbhA
sonarqube_1      | 2020.08.13 17:07:35 WARN  web[][o.s.s.a.LogOAuthWarning] For security reasons, OAuth authentication should use HTTPS. You should set the property 'Administration > Configuration > Server base URL' to a HTTPS URL.
sonarqube_1      | 2020.08.13 17:07:36 WARN  web[][o.s.a.s.w.WebService$Action] The response example is not set on action api/plugins/download
sonarqube_1      | 2020.08.13 17:07:36 WARN  web[][o.s.a.s.w.WebService$Action] The response example is not set on action api/permissions/search_templates
sonarqube_1      | 2020.08.13 17:07:36 INFO  web[][o.s.s.t.TelemetryDaemon] Sharing of SonarQube statistics is enabled.
sonarqube_1      | 2020.08.13 17:07:36 INFO  web[][o.s.s.n.NotificationDaemon] Notification service started (delay 60 sec.)
sonarqube_1      | 2020.08.13 17:07:36 INFO  web[][o.s.s.s.GeneratePluginIndex] Generate scanner plugin index
sonarqube_1      | 2020.08.13 17:07:36 INFO  web[][o.s.s.s.RegisterPlugins] Register plugins
sonarqube_1      | 2020.08.13 17:07:36 INFO  web[][o.s.s.s.RegisterMetrics] Register metrics
sonarqube_1      | 2020.08.13 17:07:36 INFO  web[][o.s.s.r.RegisterRules] Register rules
sonarqube_1      | 2020.08.13 17:07:43 INFO  web[][o.s.s.q.BuiltInQProfileRepositoryImpl] Load quality profiles
sonarqube_1      | 2020.08.13 17:07:44 INFO  web[][o.s.s.q.RegisterQualityProfiles] Register quality profiles
sonarqube_1      | 2020.08.13 17:07:44 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile css/Sonar way
sonarqube_1      | 2020.08.13 17:07:44 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile scala/Sonar way
sonarqube_1      | 2020.08.13 17:07:45 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile jsp/Sonar way
sonarqube_1      | 2020.08.13 17:07:45 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile go/Sonar way
sonarqube_1      | 2020.08.13 17:07:45 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile kotlin/Sonar way
sonarqube_1      | 2020.08.13 17:07:45 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile js/Sonar way Recommended
sonarqube_1      | 2020.08.13 17:07:45 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile js/Sonar way
sonarqube_1      | 2020.08.13 17:07:45 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile py/Sonar way
sonarqube_1      | 2020.08.13 17:07:45 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile ruby/Sonar way
sonarqube_1      | 2020.08.13 17:07:46 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile cs/Sonar way
sonarqube_1      | 2020.08.13 17:07:46 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile java/Sonar way
sonarqube_1      | 2020.08.13 17:07:46 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile web/Sonar way
sonarqube_1      | 2020.08.13 17:07:46 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile flex/Sonar way
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile xml/Sonar way
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile php/Sonar way
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile php/PSR-2
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile php/Drupal
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile vbnet/Sonar way
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile ts/Sonar way
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile ts/Sonar way recommended
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.s.RegisterPermissionTemplates] Register permission templates
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.s.RenameDeprecatedPropertyKeys] Rename deprecated property keys
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.WebServiceFilter@63b61703 [pattern=UrlPattern{inclusions=[/api/issues/delete_comment.*, ...], exclusions=[/api/properties*, ...]}]
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.DeprecatedPropertiesWsFilter@4ea72d0d [pattern=UrlPattern{inclusions=[/api/properties/*], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.WebServiceReroutingFilter@fd5f719 [pattern=UrlPattern{inclusions=[/api/components/bulk_update_key, ...], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.InitFilter@67492af [pattern=UrlPattern{inclusions=[/sessions/init/*], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.OAuth2CallbackFilter@638bc071 [pattern=UrlPattern{inclusions=[/oauth2/callback/*], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.ws.LoginAction@525375d8 [pattern=UrlPattern{inclusions=[/api/authentication/login], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.ws.LogoutAction@18864ec0 [pattern=UrlPattern{inclusions=[/api/authentication/logout], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.ws.ValidateAction@225504d6 [pattern=UrlPattern{inclusions=[/api/authentication/validate], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.q.ProjectsInWarningDaemon] Counting number of projects in warning is not started as there are no projects in this situation.
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.p.p.PlatformLevelStartup] Running Community Edition
sonarqube_1      | 2020.08.13 17:07:47 INFO  web[][o.s.s.p.Platform] WebServer is operational
sonarqube_1      | 2020.08.13 17:07:47 INFO  app[][o.s.a.SchedulerImpl] Process[web] is up
sonarqube_1      | 2020.08.13 17:07:47 INFO  app[][o.s.a.ProcessLauncherImpl] Launch process[[key='ce', ipcIndex=3, logFilenamePrefix=ce]] from [/opt/sonarqube]: /usr/local/openjdk-11/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/opt/sonarqube/temp --add-opens=java.base/java.util=ALL-UNNAMED -Xmx512m -Xms128m -XX:+HeapDumpOnOutOfMemoryError -Dhttp.nonProxyHosts=localhost|127.*|[::1] -cp ./lib/common/*:/opt/sonarqube/lib/jdbc/h2/h2-1.3.176.jar org.sonar.ce.app.CeServer /opt/sonarqube/temp/sq-process2261339428726125847properties
sonarqube_1      | 2020.08.13 17:07:48 INFO  ce[][o.s.p.ProcessEntryPoint] Starting ce
sonarqube_1      | 2020.08.13 17:07:48 INFO  ce[][o.s.ce.app.CeServer] Compute Engine starting up...
sonarqube_1      | 2020.08.13 17:07:49 INFO  ce[][o.e.p.PluginsService] no modules loaded
sonarqube_1      | 2020.08.13 17:07:49 INFO  ce[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.join.ParentJoinPlugin]
sonarqube_1      | 2020.08.13 17:07:49 INFO  ce[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
sonarqube_1      | 2020.08.13 17:07:49 INFO  ce[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
sonarqube_1      | 2020.08.13 17:07:50 INFO  ce[][o.s.s.e.EsClientProvider] Connected to local Elasticsearch: [127.0.0.1:9001]
sonarqube_1      | 2020.08.13 17:07:50 INFO  ce[][o.sonar.db.Database] Create JDBC data source for jdbc:h2:tcp://127.0.0.1:9092/sonar
sonarqube_1      | 2020.08.13 17:07:50 WARN  ce[][o.s.db.dialect.H2] H2 database should be used for evaluation purpose only.
sonarqube_1      | 2020.08.13 17:07:52 INFO  ce[][o.s.s.p.ServerFileSystemImpl] SonarQube home: /opt/sonarqube
sonarqube_1      | 2020.08.13 17:07:52 INFO  ce[][o.s.c.c.CePluginRepository] Load plugins
sonarqube_1      | 2020.08.13 17:07:53 INFO  ce[][o.s.c.c.ComputeEngineContainerImpl] Running Community edition
sonarqube_1      | 2020.08.13 17:07:53 INFO  ce[][o.s.ce.app.CeServer] Compute Engine is operational
sonarqube_1      | 2020.08.13 17:07:53 INFO  app[][o.s.a.SchedulerImpl] Process[ce] is up
sonarqube_1      | 2020.08.13 17:07:53 INFO  app[][o.s.a.SchedulerImpl] SonarQube is up
clair_1          | {"Event":"could not parse package version. skipping","Level":"warning","Location":"ubuntu.go:316","Time":"2020-08-13 17:08:29.385821","error":"invalid version","version":"0.27-1+deb7u1build0.12.04.1, 0.28-1+deb8u1"}
clair_1          | {"Event":"finished fetching","Level":"info","Location":"updater.go:242","Time":"2020-08-13 17:08:36.729838","updater name":"ubuntu"}
clair_1          | {"Event":"adding metadata to vulnerabilities","Level":"info","Location":"updater.go:268","Time":"2020-08-13 17:08:36.921407"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:37.473900","data feed name":"2002","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:37.546294","data feed name":"2003","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:37.618764","data feed name":"2004","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:37.694795","data feed name":"2005","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:37.767277","data feed name":"2006","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:37.839860","data feed name":"2007","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:37.912474","data feed name":"2008","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:37.984969","data feed name":"2009","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:38.057515","data feed name":"2010","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:38.130164","data feed name":"2011","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:38.206086","data feed name":"2012","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:38.284267","data feed name":"2013","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:38.357683","data feed name":"2014","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:38.433263","data feed name":"2015","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:38.507374","data feed name":"2016","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:38.594547","data feed name":"2017","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:38.667161","data feed name":"2018","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:38.747287","data feed name":"2019","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:08:38.820014","data feed name":"2020","error":"invalid .meta file format"}
jenkins_1        | 2020-08-13 17:10:26.120+0000 [id=61] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1        | 2020-08-13 17:10:26.122+0000 [id=61] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1        | 2020-08-13 17:10:26.123+0000 [id=61] INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 0, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1        | 2020-08-13 17:10:26.124+0000 [id=61] INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1        | 2020-08-13 17:10:26.124+0000 [id=61] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1        | 2020-08-13 17:10:26.125+0000 [id=61] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 3 ms
sonarqube_1      | 2020.08.13 17:11:22 INFO  app[][o.s.a.SchedulerImpl] Stopping SonarQube
sonarqube_1      | 2020.08.13 17:11:23 INFO  ce[][o.s.p.ProcessEntryPoint] Gracefully stopping process
sonarqube_1      | 2020.08.13 17:11:23 INFO  ce[][o.s.ce.app.CeServer] Compute Engine is stopping...
sonarqube_1      | 2020.08.13 17:11:23 INFO  ce[][o.s.c.t.CeProcessingSchedulerImpl] Gracefully stopping workers...
sonarqube_1      | 2020.08.13 17:11:23 INFO  ce[][o.s.ce.app.CeServer] Compute Engine is stopped
sonarqube_1      | 2020.08.13 17:11:23 INFO  app[][o.s.a.SchedulerImpl] Process[ce] is stopped
18-19_absace_jenkins_1 exited with code 143
sonarqube_1      | 2020.08.13 17:11:23 INFO  web[][o.s.p.ProcessEntryPoint] Gracefully stopping process
sonarqube_1      | 2020.08.13 17:11:23 INFO  web[][o.s.s.n.NotificationDaemon] Notification service stopped
sonarqube_1      | 2020.08.13 17:11:23 INFO  web[][o.s.s.p.d.EmbeddedDatabase] Embedded database stopped
sonarqube_1      | 2020.08.13 17:11:23 INFO  web[][o.s.s.app.WebServer] WebServer stopped
sonarqube_1      | 2020.08.13 17:11:23 INFO  app[][o.s.a.SchedulerImpl] Process[web] is stopped
sonarqube_1      | 2020.08.13 17:11:23 INFO  app[][o.s.a.SchedulerImpl] Process[es] is stopped
sonarqube_1      | 2020.08.13 17:11:23 INFO  app[][o.s.a.SchedulerImpl] SonarQube is stopped
sonarqube_1      | 2020.08.13 17:11:23 WARN  app[][o.s.a.p.AbstractManagedProcess] Process exited with exit value [es]: 143
18-19_absace_sonarqube_1 exited with code 143
18-19_absace_clairctl_1 exited with code 137
clair_1          | {"Event":"Received interruption, gracefully stopping ...","Level":"info","Location":"main.go:116","Time":"2020-08-13 17:11:32.787928"}
clair_1          | {"Event":"health API stopped","Level":"info","Location":"api.go:98","Time":"2020-08-13 17:11:32.788031"}
clair_1          | {"Event":"main API stopped","Level":"info","Location":"api.go:74","Time":"2020-08-13 17:11:32.788120"}
clair_1          | {"Event":"updater service stopped","Level":"info","Location":"updater.go:161","Time":"2020-08-13 17:11:33.445121"}
postgres_1       | LOG:  could not receive data from client: Connection reset by peer
18-19_absace_clair_1 exited with code 0
postgres_1       | LOG:  received smart shutdown request
postgres_1       | LOG:  autovacuum launcher shutting down
postgres_1       | LOG:  shutting down
postgres_1       | LOG:  database system is shut down
18-19_absace_postgres_1 exited with code 0
ubuntu@ip-172-31-41-31:~/18-19_absace$ docker-compose up
Starting 18-19_absace_jenkins_1         ... done
Starting 18-19_absace_postgres_1  ... done
Starting 18-19_absace_sonarqube_1 ... done
Starting 18-19_absace_clair_1     ... done
Recreating 18-19_absace_clair-scanner_1 ... done
Starting 18-19_absace_clairctl_1        ... done
Attaching to 18-19_absace_postgres_1, 18-19_absace_sonarqube_1, 18-19_absace_clair_1, 18-19_absace_jenkins_1, 18-19_absace_clairctl_1, 18-19_absace_clair-scanner_1
clair_1          | {"Event":"running database migrations","Level":"info","Location":"pgsql.go:216","Time":"2020-08-13 17:12:49.128615"}
clair_1          | {"Event":"database migration ran successfully","Level":"info","Location":"pgsql.go:223","Time":"2020-08-13 17:12:49.134841"}
clair_1          | {"Event":"notifier service is disabled","Level":"info","Location":"notifier.go:77","Time":"2020-08-13 17:12:49.135012"}
clair_1          | {"Event":"starting main API","Level":"info","Location":"api.go:52","Time":"2020-08-13 17:12:49.135055","port":6060}
clair_1          | {"Event":"starting health API","Level":"info","Location":"api.go:85","Time":"2020-08-13 17:12:49.135435","port":6061}
clair_1          | {"Event":"updater service started","Level":"info","Location":"updater.go:81","Time":"2020-08-13 17:12:49.135547","lock identifier":"f96878c5-6007-4a6f-ae80-5719c0ca3ed3"}
clair_1          | {"Event":"updating vulnerabilities","Level":"info","Location":"updater.go:182","Time":"2020-08-13 17:12:49.138984"}
clair_1          | {"Event":"fetching vulnerability updates","Level":"info","Location":"updater.go:228","Time":"2020-08-13 17:12:49.139175"}
clair_1          | {"Event":"Start fetching vulnerabilities","Level":"info","Location":"debian.go:63","Time":"2020-08-13 17:12:49.139240","package":"Debian"}
clair_1          | {"Event":"Start fetching vulnerabilities","Level":"info","Location":"oracle.go:119","Time":"2020-08-13 17:12:49.140039","package":"Oracle Linux"}
clair_1          | {"Event":"Start fetching vulnerabilities","Level":"info","Location":"alpine.go:52","Time":"2020-08-13 17:12:49.140996","package":"Alpine"}
clair_1          | {"Event":"Start fetching vulnerabilities","Level":"info","Location":"ubuntu.go:85","Time":"2020-08-13 17:12:49.141498","package":"Ubuntu"}
clair_1          | {"Event":"Start fetching vulnerabilities","Level":"info","Location":"rhel.go:92","Time":"2020-08-13 17:12:49.142172","package":"RHEL"}
clair_1          | {"Event":"finished fetching","Level":"info","Location":"updater.go:242","Time":"2020-08-13 17:12:49.368334","updater name":"rhel"}
clair_1          | {"Event":"finished fetching","Level":"info","Location":"updater.go:242","Time":"2020-08-13 17:12:49.801306","updater name":"oracle"}
postgres_1       |
postgres_1       | PostgreSQL Database directory appears to contain a database; Skipping initialization
postgres_1       |
postgres_1       | LOG:  database system was shut down at 2020-08-13 17:11:33 UTC
postgres_1       | LOG:  MultiXact member wraparound protections are now enabled
postgres_1       | LOG:  autovacuum launcher started
postgres_1       | LOG:  database system is ready to accept connections
sonarqube_1      | 2020.08.13 17:07:20 WARN  es[][o.e.b.BootstrapChecks] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
sonarqube_1      | 2020.08.13 17:07:24 INFO  es[][o.e.c.s.MasterService] zen-disco-elected-as-master ([0] nodes joined), reason: new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{ndDrqE74RBKZJXprsVgWOg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}
sonarqube_1      | 2020.08.13 17:07:24 INFO  es[][o.e.c.s.ClusterApplierService] new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{ndDrqE74RBKZJXprsVgWOg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}, reason: apply cluster state (from master [master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{ndDrqE74RBKZJXprsVgWOg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube} committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])
sonarqube_1      | 2020.08.13 17:07:24 INFO  es[][o.e.n.Node] started
sonarqube_1      | 2020.08.13 17:07:24 INFO  es[][o.e.g.GatewayService] recovered [7] indices into cluster_state
sonarqube_1      | 2020.08.13 17:07:26 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[metadatas][0], [components][2], [components][1]] ...]).
sonarqube_1      | 2020.08.13 17:11:23 INFO  es[][o.e.n.Node] stopping ...
sonarqube_1      | 2020.08.13 17:11:23 INFO  es[][o.e.n.Node] stopped
sonarqube_1      | 2020.08.13 17:11:23 INFO  es[][o.e.n.Node] closing ...
sonarqube_1      | 2020.08.13 17:11:23 INFO  es[][o.e.n.Node] closed
sonarqube_1      | 2020.08.13 17:12:49 INFO  app[][o.s.a.AppFileSystem] Cleaning or creating temp directory /opt/sonarqube/temp
sonarqube_1      | 2020.08.13 17:12:49 INFO  app[][o.s.a.es.EsSettings] Elasticsearch listening on /127.0.0.1:9001
sonarqube_1      | 2020.08.13 17:12:49 INFO  app[][o.s.a.ProcessLauncherImpl] Launch process[[key='es', ipcIndex=1, logFilenamePrefix=es]] from [/opt/sonarqube/elasticsearch]: /opt/sonarqube/elasticsearch/bin/elasticsearch
sonarqube_1      | 2020.08.13 17:12:49 INFO  app[][o.s.a.SchedulerImpl] Waiting for Elasticsearch to be up and running
18-19_absace_clair-scanner_1 exited with code 0
jenkins_1        | Running from: /usr/share/jenkins/jenkins.war
jenkins_1        | webroot: EnvVars.masterEnvVars.get("JENKINS_HOME")
clair_1          | {"Event":"finished fetching","Level":"info","Location":"updater.go:242","Time":"2020-08-13 17:12:50.277037","updater name":"alpine"}
jenkins_1        | 2020-08-13 17:12:50.385+0000 [id=1]  INFO    org.eclipse.jetty.util.log.Log#initialized: Logging initialized @615ms to org.eclipse.jetty.util.log.JavaUtilLog
sonarqube_1      | 2020.08.13 17:12:50 INFO  app[][o.e.p.PluginsService] no modules loaded
sonarqube_1      | 2020.08.13 17:12:50 INFO  app[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
sonarqube_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
clair_1          | {"Event":"Debian bullseye is not mapped to any version number (eg. Jessie-\u003e8). Please update me.","Level":"warning","Location":"debian.go:134","Time":"2020-08-13 17:12:50.509544"}
clair_1          | {"Event":"finished fetching","Level":"info","Location":"updater.go:242","Time":"2020-08-13 17:12:50.509846","updater name":"debian"}
jenkins_1        | 2020-08-13 17:12:50.538+0000 [id=1]  INFO    winstone.Logger#logInternal: Beginning extraction from war file
jenkins_1        | 2020-08-13 17:12:50.606+0000 [id=1]  WARNING o.e.j.s.handler.ContextHandler#setContextPath: Empty contextPath
jenkins_1        | 2020-08-13 17:12:50.751+0000 [id=1]  INFO    org.eclipse.jetty.server.Server#doStart: jetty-9.4.27.v20200227; built: 2020-02-27T18:37:21.340Z; git: a304fd9f351f337e7c0e2a7c28878dd536149c6c; jvm 1.8.0_242-b08
jenkins_1        | 2020-08-13 17:12:51.139+0000 [id=1]  INFO    o.e.j.w.StandardDescriptorProcessor#visitServlet: NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
jenkins_1        | 2020-08-13 17:12:51.230+0000 [id=1]  INFO    o.e.j.s.s.DefaultSessionIdManager#doStart: DefaultSessionIdManager workerName=node0
jenkins_1        | 2020-08-13 17:12:51.231+0000 [id=1]  INFO    o.e.j.s.s.DefaultSessionIdManager#doStart: No SessionScavenger set, using defaults
jenkins_1        | 2020-08-13 17:12:51.246+0000 [id=1]  INFO    o.e.j.server.session.HouseKeeper#startScavenging: node0 Scavenging every 600000ms
jenkins_1        | 2020-08-13 17:12:51.761+0000 [id=1]  INFO    hudson.WebAppMain#contextInitialized: Jenkins home directory: /var/jenkins_home found at: EnvVars.masterEnvVars.get("JENKINS_HOME")
jenkins_1        | 2020-08-13 17:12:51.889+0000 [id=1]  INFO    o.e.j.s.handler.ContextHandler#doStart: Started w.@4470fbd6{Jenkins v2.235.3,/,file:///var/jenkins_home/war/,AVAILABLE}{/var/jenkins_home/war}
jenkins_1        | 2020-08-13 17:12:51.957+0000 [id=1]  INFO    o.e.j.server.AbstractConnector#doStart: Started ServerConnector@5315b42e{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}
jenkins_1        | 2020-08-13 17:12:51.961+0000 [id=1]  INFO    org.eclipse.jetty.server.Server#doStart: Started @2191ms
jenkins_1        | 2020-08-13 17:12:51.962+0000 [id=21] INFO    winstone.Logger#logInternal: Winstone Servlet Engine running: controlPort=disabled
jenkins_1        | 2020-08-13 17:12:53.570+0000 [id=27] INFO    jenkins.InitReactorRunner$1#onAttained: Started initialization
sonarqube_1      | 2020.08.13 17:12:53 INFO  es[][o.e.e.NodeEnvironment] using [1] data paths, mounts [[/opt/sonarqube/data (/dev/xvda1)]], net usable_space [15.1gb], net total_space [29gb], types [ext4]
sonarqube_1      | 2020.08.13 17:12:53 INFO  es[][o.e.e.NodeEnvironment] heap size [494.9mb], compressed ordinary object pointers [true]
sonarqube_1      | 2020.08.13 17:12:53 INFO  es[][o.e.n.Node] node name [sonarqube], node ID [OspwetY9T2i0OWqdt0vgOg]
sonarqube_1      | 2020.08.13 17:12:53 INFO  es[][o.e.n.Node] version[6.8.0], pid[30], build[default/tar/65b6179/2019-05-15T20:06:13.172855Z], OS[Linux/5.3.0-1032-aws/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/11.0.8/11.0.8+10]
sonarqube_1      | 2020.08.13 17:12:53 INFO  es[][o.e.n.Node] JVM arguments [-XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=/opt/sonarqube/temp, -XX:ErrorFile=../logs/es_hs_err_pid%p.log, -Xms512m, -Xmx512m, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/opt/sonarqube/elasticsearch, -Des.path.conf=/opt/sonarqube/temp/conf/es, -Des.distribution.flavor=default, -Des.distribution.type=tar]
jenkins_1        | 2020-08-13 17:12:53.976+0000 [id=27] INFO    jenkins.InitReactorRunner$1#onAttained: Listed all plugins
sonarqube_1      | 2020.08.13 17:12:54 INFO  es[][o.e.p.PluginsService] loaded module [analysis-common]
sonarqube_1      | 2020.08.13 17:12:54 INFO  es[][o.e.p.PluginsService] loaded module [lang-painless]
sonarqube_1      | 2020.08.13 17:12:54 INFO  es[][o.e.p.PluginsService] loaded module [mapper-extras]
sonarqube_1      | 2020.08.13 17:12:54 INFO  es[][o.e.p.PluginsService] loaded module [parent-join]
sonarqube_1      | 2020.08.13 17:12:54 INFO  es[][o.e.p.PluginsService] loaded module [percolator]
sonarqube_1      | 2020.08.13 17:12:54 INFO  es[][o.e.p.PluginsService] loaded module [reindex]
sonarqube_1      | 2020.08.13 17:12:54 INFO  es[][o.e.p.PluginsService] loaded module [repository-url]
sonarqube_1      | 2020.08.13 17:12:54 INFO  es[][o.e.p.PluginsService] loaded module [transport-netty4]
sonarqube_1      | 2020.08.13 17:12:54 INFO  es[][o.e.p.PluginsService] no plugins loaded
sonarqube_1      | 2020.08.13 17:12:56 WARN  es[][o.e.d.c.s.Settings] [http.enabled] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version.
sonarqube_1      | 2020.08.13 17:12:57 INFO  es[][o.e.d.DiscoveryModule] using discovery type [zen] and host providers [settings]
sonarqube_1      | 2020.08.13 17:12:57 INFO  es[][o.e.n.Node] initialized
sonarqube_1      | 2020.08.13 17:12:57 INFO  es[][o.e.n.Node] starting ...
sonarqube_1      | 2020.08.13 17:12:58 INFO  es[][o.e.t.TransportService] publish_address {127.0.0.1:9001}, bound_addresses {127.0.0.1:9001}
sonarqube_1      | 2020.08.13 17:12:58 WARN  es[][o.e.b.BootstrapChecks] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
jenkins_1        | 2020-08-13 17:13:01.742+0000 [id=29] INFO    jenkins.InitReactorRunner$1#onAttained: Prepared all plugins
jenkins_1        | 2020-08-13 17:13:01.777+0000 [id=28] INFO    jenkins.InitReactorRunner$1#onAttained: Started all plugins
sonarqube_1      | 2020.08.13 17:13:01 INFO  es[][o.e.c.s.MasterService] zen-disco-elected-as-master ([0] nodes joined), reason: new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{9hJXHFmeQEKQe2mixYY3rQ}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}
sonarqube_1      | 2020.08.13 17:13:01 INFO  es[][o.e.c.s.ClusterApplierService] new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{9hJXHFmeQEKQe2mixYY3rQ}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}, reason: apply cluster state (from master [master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{9hJXHFmeQEKQe2mixYY3rQ}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube} committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])
sonarqube_1      | 2020.08.13 17:13:01 INFO  es[][o.e.n.Node] started
sonarqube_1      | 2020.08.13 17:13:02 INFO  es[][o.e.g.GatewayService] recovered [7] indices into cluster_state
sonarqube_1      | 2020.08.13 17:13:03 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[metadatas][0]] ...]).
sonarqube_1      | 2020.08.13 17:13:03 INFO  app[][o.s.a.SchedulerImpl] Process[es] is up
sonarqube_1      | 2020.08.13 17:13:03 INFO  app[][o.s.a.ProcessLauncherImpl] Launch process[[key='web', ipcIndex=2, logFilenamePrefix=web]] from [/opt/sonarqube]: /usr/local/openjdk-11/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/opt/sonarqube/temp --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.rmi/sun.rmi.transport=ALL-UNNAMED -Xmx512m -Xms128m -XX:+HeapDumpOnOutOfMemoryError -Djava.security.egd=file:/dev/./urandom -Dhttp.nonProxyHosts=localhost|127.*|[::1] -cp ./lib/common/*:/opt/sonarqube/lib/jdbc/h2/h2-1.3.176.jar org.sonar.server.app.WebServer /opt/sonarqube/temp/sq-process9530421039825968689properties
jenkins_1        | 2020-08-13 17:13:03.849+0000 [id=32] WARNING o.j.p.d.DockerBuilder$DescriptorImpl#<init>: Docker URL is not set, docker client won't be initialized
jenkins_1        | 2020-08-13 17:13:03.988+0000 [id=32] INFO    jenkins.InitReactorRunner$1#onAttained: Augmented all extensions
jenkins_1        | 2020-08-13 17:13:04.058+0000 [id=30] INFO    jenkins.InitReactorRunner$1#onAttained: System config loaded
jenkins_1        | 2020-08-13 17:13:04.071+0000 [id=31] INFO    jenkins.InitReactorRunner$1#onAttained: System config adapted
jenkins_1        | 2020-08-13 17:13:04.247+0000 [id=27] INFO    jenkins.InitReactorRunner$1#onAttained: Loaded all jobs
jenkins_1        | 2020-08-13 17:13:04.250+0000 [id=31] INFO    jenkins.InitReactorRunner$1#onAttained: Configuration for all jobs updated
jenkins_1        | 2020-08-13 17:13:04.295+0000 [id=46] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started Download metadata
jenkins_1        | 2020-08-13 17:13:04.313+0000 [id=46] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished Download metadata. 7 ms
sonarqube_1      | 2020.08.13 17:13:04 INFO  web[][o.s.p.ProcessEntryPoint] Starting web
jenkins_1        | 2020-08-13 17:13:04.753+0000 [id=28] INFO    o.s.c.s.AbstractApplicationContext#prepareRefresh: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@4c9c0970: display name [Root WebApplicationContext]; startup date [Thu Aug 13 17:13:04 UTC 2020]; root of context hierarchy
jenkins_1        | 2020-08-13 17:13:04.754+0000 [id=28] INFO    o.s.c.s.AbstractApplicationContext#obtainFreshBeanFactory: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@4c9c0970]: org.springframework.beans.factory.support.DefaultListableBeanFactory@5eec6cd
jenkins_1        | 2020-08-13 17:13:04.765+0000 [id=28] INFO    o.s.b.f.s.DefaultListableBeanFactory#preInstantiateSingletons: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@5eec6cd: defining beans [authenticationManager]; root of factory hierarchy
jenkins_1        | 2020-08-13 17:13:04.993+0000 [id=28] INFO    o.s.c.s.AbstractApplicationContext#prepareRefresh: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@12ee0cf6: display name [Root WebApplicationContext]; startup date [Thu Aug 13 17:13:04 UTC 2020]; root of context hierarchy
jenkins_1        | 2020-08-13 17:13:04.994+0000 [id=28] INFO    o.s.c.s.AbstractApplicationContext#obtainFreshBeanFactory: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@12ee0cf6]: org.springframework.beans.factory.support.DefaultListableBeanFactory@6d113b5b
jenkins_1        | 2020-08-13 17:13:04.995+0000 [id=28] INFO    o.s.b.f.s.DefaultListableBeanFactory#preInstantiateSingletons: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@6d113b5b: defining beans [filter,legacy]; root of factory hierarchy
jenkins_1        | 2020-08-13 17:13:05.068+0000 [id=29] INFO    jenkins.InitReactorRunner$1#onAttained: Completed initialization
jenkins_1        | 2020-08-13 17:13:05.276+0000 [id=20] INFO    hudson.WebAppMain$3#run: Jenkins is fully up and running
sonarqube_1      | 2020.08.13 17:13:05 INFO  web[][o.a.t.u.n.NioSelectorPool] Using a shared selector for servlet write/read
sonarqube_1      | 2020.08.13 17:13:06 INFO  web[][o.e.p.PluginsService] no modules loaded
sonarqube_1      | 2020.08.13 17:13:06 INFO  web[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.join.ParentJoinPlugin]
sonarqube_1      | 2020.08.13 17:13:06 INFO  web[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
sonarqube_1      | 2020.08.13 17:13:06 INFO  web[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
sonarqube_1      | 2020.08.13 17:13:07 INFO  web[][o.s.s.e.EsClientProvider] Connected to local Elasticsearch: [127.0.0.1:9001]
sonarqube_1      | 2020.08.13 17:13:07 INFO  web[][o.s.s.p.LogServerVersion] SonarQube Server / 7.9.4.35981 / 0a370ee33e97c5d5e3a038a3f7dc4c0162319835
sonarqube_1      | 2020.08.13 17:13:07 INFO  web[][o.s.s.p.d.EmbeddedDatabase] Starting embedded database on port 9092 with url jdbc:h2:tcp://127.0.0.1:9092/sonar
sonarqube_1      | 2020.08.13 17:13:07 INFO  web[][o.s.s.p.d.EmbeddedDatabase] Embedded database started. Data stored in: /opt/sonarqube/data
sonarqube_1      | 2020.08.13 17:13:07 INFO  web[][o.sonar.db.Database] Create JDBC data source for jdbc:h2:tcp://127.0.0.1:9092/sonar
sonarqube_1      | 2020.08.13 17:13:07 WARN  web[][o.s.db.dialect.H2] H2 database should be used for evaluation purpose only.
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerFileSystemImpl] SonarQube home: /opt/sonarqube
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.u.SystemPasscodeImpl] System authentication by passcode is disabled
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin Git / 1.8.0.1574 / aec3dc8f5228aabd218e1cd31ac6e6515a43715d
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin GitHub Authentication for SonarQube / 1.5.0.870 / 153f7c7af7a264adb0fcbe5fee87bdd140a6a3a1
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin JaCoCo / 1.0.2.475 / b79a4724f3a9af1051266b4f8ca0460977295ead
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin LDAP / 2.2.0.608 / 79dc3fa4393a29667673c70182f3016288b548b7
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SAML 2.0 Authentication for SonarQube / 1.2.0.682 / 44d64e660a3c7f235962a7bcfef78bf8c87db98a
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarC# / 7.15.0.8572 / e0ad49e38a28a8fc333ba746fc998e48678f6a8b
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarCSS / 1.1.1.1010 / 365e21fd0cb9035669fc59f6fec7c8fd28a7303b
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarFlex / 2.5.1.1831 / a0c44437f6abb0feec76edd073f91fec64db2a6c
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarGo / 1.1.1.2000 / 40d55921c7a63b67386a053490d17b6723a46cd5
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarHTML / 3.1.0.1615 / 4181edb5eff5605bec82dc0aa15ecd70eaa5857f
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarJS / 5.2.1.7778 / 49f34eaeaad59868d4353d89b1fc5c02bbe51976
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarJava / 5.13.1.18282 / 568f8ed2349f48e250a9329895b9a870100dfbeb
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarKotlin / 1.5.0.315 / 4ff3a145a58f3f84f1b39846a205a129d742e993
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarPHP / 3.2.0.4868 / ec66bd5f8490677eb0ebae82aa17c2a5d9c0e5e7
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarPython / 1.14.1.3143 / eed7b315b6116fe462a19c771013bf3891c92a97
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarRuby / 1.5.0.315 / 4ff3a145a58f3f84f1b39846a205a129d742e993
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarScala / 1.5.0.315 / 4ff3a145a58f3f84f1b39846a205a129d742e993
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarTS / 1.9.0.3766 / 4a4080b78001a78d758d1d0fa0190fb9496b6f57
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarVB / 7.15.0.8572 / e0ad49e38a28a8fc333ba746fc998e48678f6a8b
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarXML / 2.0.1.2020 / c5b84004face582d56f110e24c29bf9c6a679e69
sonarqube_1      | 2020.08.13 17:13:08 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin Svn / 1.9.0.1295 / 942e075773975354e32691a60bfd968065703e04
sonarqube_1      | 2020.08.13 17:13:09 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.WebServiceFilter@70228495 [pattern=UrlPattern{inclusions=[/api/system/migrate_db.*, ...], exclusions=[/api/properties*, ...]}]
sonarqube_1      | 2020.08.13 17:13:09 INFO  web[][o.s.s.a.EmbeddedTomcat] HTTP connector enabled on port 9000
sonarqube_1      | 2020.08.13 17:13:10 INFO  web[][o.s.s.p.UpdateCenterClient] Update center: https://update.sonarsource.org/update-center.properties (no proxy)
sonarqube_1      | 2020.08.13 17:13:11 INFO  web[][o.s.s.s.LogServerId] Server ID: BF41A1F2-AXOwq_Q3V0p2MHt8HbhA
sonarqube_1      | 2020.08.13 17:13:11 WARN  web[][o.s.s.a.LogOAuthWarning] For security reasons, OAuth authentication should use HTTPS. You should set the property 'Administration > Configuration > Server base URL' to a HTTPS URL.
sonarqube_1      | 2020.08.13 17:13:11 WARN  web[][o.s.a.s.w.WebService$Action] The response example is not set on action api/plugins/download
sonarqube_1      | 2020.08.13 17:13:11 WARN  web[][o.s.a.s.w.WebService$Action] The response example is not set on action api/permissions/search_templates
sonarqube_1      | 2020.08.13 17:13:11 INFO  web[][o.s.s.t.TelemetryDaemon] Sharing of SonarQube statistics is enabled.
sonarqube_1      | 2020.08.13 17:13:11 INFO  web[][o.s.s.n.NotificationDaemon] Notification service started (delay 60 sec.)
sonarqube_1      | 2020.08.13 17:13:12 INFO  web[][o.s.s.s.GeneratePluginIndex] Generate scanner plugin index
sonarqube_1      | 2020.08.13 17:13:12 INFO  web[][o.s.s.s.RegisterPlugins] Register plugins
sonarqube_1      | 2020.08.13 17:13:12 INFO  web[][o.s.s.s.RegisterMetrics] Register metrics
sonarqube_1      | 2020.08.13 17:13:12 INFO  web[][o.s.s.r.RegisterRules] Register rules
sonarqube_1      | 2020.08.13 17:13:19 INFO  web[][o.s.s.q.BuiltInQProfileRepositoryImpl] Load quality profiles
sonarqube_1      | 2020.08.13 17:13:20 INFO  web[][o.s.s.q.RegisterQualityProfiles] Register quality profiles
sonarqube_1      | 2020.08.13 17:13:20 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile css/Sonar way
sonarqube_1      | 2020.08.13 17:13:20 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile scala/Sonar way
sonarqube_1      | 2020.08.13 17:13:20 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile jsp/Sonar way
sonarqube_1      | 2020.08.13 17:13:20 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile go/Sonar way
sonarqube_1      | 2020.08.13 17:13:20 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile kotlin/Sonar way
sonarqube_1      | 2020.08.13 17:13:20 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile js/Sonar way Recommended
sonarqube_1      | 2020.08.13 17:13:20 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile js/Sonar way
sonarqube_1      | 2020.08.13 17:13:21 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile py/Sonar way
sonarqube_1      | 2020.08.13 17:13:21 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile ruby/Sonar way
sonarqube_1      | 2020.08.13 17:13:21 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile cs/Sonar way
sonarqube_1      | 2020.08.13 17:13:21 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile java/Sonar way
sonarqube_1      | 2020.08.13 17:13:21 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile web/Sonar way
sonarqube_1      | 2020.08.13 17:13:21 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile flex/Sonar way
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile xml/Sonar way
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile php/Sonar way
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile php/PSR-2
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile php/Drupal
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile vbnet/Sonar way
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile ts/Sonar way
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile ts/Sonar way recommended
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.s.RegisterPermissionTemplates] Register permission templates
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.s.RenameDeprecatedPropertyKeys] Rename deprecated property keys
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.WebServiceFilter@5598ec47 [pattern=UrlPattern{inclusions=[/api/issues/delete_comment.*, ...], exclusions=[/api/properties*, ...]}]
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.DeprecatedPropertiesWsFilter@40f0854f [pattern=UrlPattern{inclusions=[/api/properties/*], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.WebServiceReroutingFilter@131c0937 [pattern=UrlPattern{inclusions=[/api/components/bulk_update_key, ...], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.InitFilter@5bfd2a9 [pattern=UrlPattern{inclusions=[/sessions/init/*], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.OAuth2CallbackFilter@778cb35d [pattern=UrlPattern{inclusions=[/oauth2/callback/*], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.ws.LoginAction@4a7ee250 [pattern=UrlPattern{inclusions=[/api/authentication/login], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.ws.LogoutAction@e3c92f7 [pattern=UrlPattern{inclusions=[/api/authentication/logout], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.ws.ValidateAction@782b7c9f [pattern=UrlPattern{inclusions=[/api/authentication/validate], exclusions=[]}]
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.q.ProjectsInWarningDaemon] Counting number of projects in warning is not started as there are no projects in this situation.
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.p.p.PlatformLevelStartup] Running Community Edition
sonarqube_1      | 2020.08.13 17:13:22 INFO  web[][o.s.s.p.Platform] WebServer is operational
sonarqube_1      | 2020.08.13 17:13:23 INFO  app[][o.s.a.SchedulerImpl] Process[web] is up
sonarqube_1      | 2020.08.13 17:13:23 INFO  app[][o.s.a.ProcessLauncherImpl] Launch process[[key='ce', ipcIndex=3, logFilenamePrefix=ce]] from [/opt/sonarqube]: /usr/local/openjdk-11/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/opt/sonarqube/temp --add-opens=java.base/java.util=ALL-UNNAMED -Xmx512m -Xms128m -XX:+HeapDumpOnOutOfMemoryError -Dhttp.nonProxyHosts=localhost|127.*|[::1] -cp ./lib/common/*:/opt/sonarqube/lib/jdbc/h2/h2-1.3.176.jar org.sonar.ce.app.CeServer /opt/sonarqube/temp/sq-process18001268480230808737properties
sonarqube_1      | 2020.08.13 17:13:23 INFO  ce[][o.s.p.ProcessEntryPoint] Starting ce
sonarqube_1      | 2020.08.13 17:13:23 INFO  ce[][o.s.ce.app.CeServer] Compute Engine starting up...
sonarqube_1      | 2020.08.13 17:13:24 INFO  ce[][o.e.p.PluginsService] no modules loaded
sonarqube_1      | 2020.08.13 17:13:24 INFO  ce[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.join.ParentJoinPlugin]
sonarqube_1      | 2020.08.13 17:13:24 INFO  ce[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
sonarqube_1      | 2020.08.13 17:13:24 INFO  ce[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
sonarqube_1      | 2020.08.13 17:13:26 INFO  ce[][o.s.s.e.EsClientProvider] Connected to local Elasticsearch: [127.0.0.1:9001]
sonarqube_1      | 2020.08.13 17:13:26 INFO  ce[][o.sonar.db.Database] Create JDBC data source for jdbc:h2:tcp://127.0.0.1:9092/sonar
sonarqube_1      | 2020.08.13 17:13:26 WARN  ce[][o.s.db.dialect.H2] H2 database should be used for evaluation purpose only.
sonarqube_1      | 2020.08.13 17:13:27 INFO  ce[][o.s.s.p.ServerFileSystemImpl] SonarQube home: /opt/sonarqube
sonarqube_1      | 2020.08.13 17:13:27 INFO  ce[][o.s.c.c.CePluginRepository] Load plugins
sonarqube_1      | 2020.08.13 17:13:28 INFO  ce[][o.s.c.c.ComputeEngineContainerImpl] Running Community edition
sonarqube_1      | 2020.08.13 17:13:28 INFO  ce[][o.s.ce.app.CeServer] Compute Engine is operational
sonarqube_1      | 2020.08.13 17:13:29 INFO  app[][o.s.a.SchedulerImpl] Process[ce] is up
sonarqube_1      | 2020.08.13 17:13:29 INFO  app[][o.s.a.SchedulerImpl] SonarQube is up
clair_1          | {"Event":"could not parse package version. skipping","Level":"warning","Location":"ubuntu.go:316","Time":"2020-08-13 17:14:10.387458","error":"invalid version","version":"0.27-1+deb7u1build0.12.04.1, 0.28-1+deb8u1"}
clair_1          | {"Event":"finished fetching","Level":"info","Location":"updater.go:242","Time":"2020-08-13 17:14:13.518113","updater name":"ubuntu"}
clair_1          | {"Event":"adding metadata to vulnerabilities","Level":"info","Location":"updater.go:268","Time":"2020-08-13 17:14:13.820230"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:14.414576","data feed name":"2002","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:14.507628","data feed name":"2003","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:14.575172","data feed name":"2004","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:14.648473","data feed name":"2005","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:14.716017","data feed name":"2006","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:14.783596","data feed name":"2007","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:14.851483","data feed name":"2008","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:14.918931","data feed name":"2009","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:14.988940","data feed name":"2010","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:15.056569","data feed name":"2011","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:15.124935","data feed name":"2012","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:15.192664","data feed name":"2013","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:15.269106","data feed name":"2014","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:15.338203","data feed name":"2015","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:15.405857","data feed name":"2016","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:15.473384","data feed name":"2017","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:15.540983","data feed name":"2018","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:15.609448","data feed name":"2019","error":"invalid .meta file format"}
clair_1          | {"Event":"could not get NVD data feed hash","Level":"warning","Location":"nvd.go:137","Time":"2020-08-13 17:14:15.677069","data feed name":"2020","error":"invalid .meta file format"}
jenkins_1        | 2020-08-13 17:17:12.990+0000 [id=62] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1        | 2020-08-13 17:17:12.992+0000 [id=62] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1        | 2020-08-13 17:17:12.994+0000 [id=62] INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 0, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1        | 2020-08-13 17:17:12.994+0000 [id=62] INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1        | 2020-08-13 17:17:12.995+0000 [id=62] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1        | 2020-08-13 17:17:12.995+0000 [id=62] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 5 ms
clair_1          | {"Event":"fetcher note","Level":"warning","Location":"updater.go:204","Time":"2020-08-13 17:18:36.397396","note":"Debian bullseye is not mapped to any version number (eg. Jessie-\u003e8). Please update me."}
clair_1          | {"Event":"fetcher note","Level":"warning","Location":"updater.go:204","Time":"2020-08-13 17:18:36.397453","note":"Ubuntu focal is not mapped to any version number (eg. trusty-\u003e14.04). Please update me."}
clair_1          | {"Event":"fetcher note","Level":"warning","Location":"updater.go:204","Time":"2020-08-13 17:18:36.397478","note":"Ubuntu snap is not mapped to any version number (eg. trusty-\u003e14.04). Please update me."}
clair_1          | {"Event":"fetcher note","Level":"warning","Location":"updater.go:204","Time":"2020-08-13 17:18:36.397493","note":"Ubuntu cosmic is not mapped to any version number (eg. trusty-\u003e14.04). Please update me."}
clair_1          | {"Event":"fetcher note","Level":"warning","Location":"updater.go:204","Time":"2020-08-13 17:18:36.397510","note":"Ubuntu disco is not mapped to any version number (eg. trusty-\u003e14.04). Please update me."}
clair_1          | {"Event":"fetcher note","Level":"warning","Location":"updater.go:204","Time":"2020-08-13 17:18:36.397533","note":"Ubuntu eoan is not mapped to any version number (eg. trusty-\u003e14.04). Please update me."}
clair_1          | {"Event":"update finished","Level":"info","Location":"updater.go:213","Time":"2020-08-13 17:18:36.398651"}
jenkins_1        | 2020-08-13 17:22:12.990+0000 [id=63] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1        | 2020-08-13 17:22:12.991+0000 [id=63] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1        | 2020-08-13 17:22:12.991+0000 [id=63] INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 1, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1        | 2020-08-13 17:22:12.991+0000 [id=63] INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1        | 2020-08-13 17:22:12.991+0000 [id=63] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1        | 2020-08-13 17:22:12.992+0000 [id=63] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
jenkins_1        | 2020-08-13 17:23:23.794+0000 [id=22] INFO    winstone.Logger#logInternal: JVM is terminating. Shutting down Jetty
sonarqube_1      | 2020.08.13 17:23:23 INFO  app[][o.s.a.SchedulerImpl] Stopping SonarQube
sonarqube_1      | 2020.08.13 17:23:24 INFO  ce[][o.s.p.ProcessEntryPoint] Gracefully stopping process
sonarqube_1      | 2020.08.13 17:23:24 INFO  ce[][o.s.ce.app.CeServer] Compute Engine is stopping...
sonarqube_1      | 2020.08.13 17:23:24 INFO  ce[][o.s.c.t.CeProcessingSchedulerImpl] Gracefully stopping workers...
sonarqube_1      | 2020.08.13 17:23:24 INFO  ce[][o.s.ce.app.CeServer] Compute Engine is stopped
sonarqube_1      | 2020.08.13 17:23:24 INFO  app[][o.s.a.SchedulerImpl] Process[ce] is stopped
sonarqube_1      | 2020.08.13 17:23:24 INFO  web[][o.s.p.ProcessEntryPoint] Gracefully stopping process
sonarqube_1      | 2020.08.13 17:23:24 INFO  web[][o.s.s.n.NotificationDaemon] Notification service stopped
sonarqube_1      | 2020.08.13 17:23:24 INFO  web[][o.s.s.p.d.EmbeddedDatabase] Embedded database stopped
18-19_absace_jenkins_1 exited with code 143
sonarqube_1      | 2020.08.13 17:23:24 INFO  web[][o.s.s.app.WebServer] WebServer stopped
sonarqube_1      | 2020.08.13 17:23:24 INFO  app[][o.s.a.SchedulerImpl] Process[web] is stopped
sonarqube_1      | 2020.08.13 17:23:24 INFO  app[][o.s.a.SchedulerImpl] Process[es] is stopped
sonarqube_1      | 2020.08.13 17:23:24 WARN  app[][o.s.a.p.AbstractManagedProcess] Process exited with exit value [es]: 143
sonarqube_1      | 2020.08.13 17:23:24 INFO  app[][o.s.a.SchedulerImpl] SonarQube is stopped
18-19_absace_sonarqube_1 exited with code 143
18-19_absace_clairctl_1 exited with code 137
clair_1          | {"Event":"Received interruption, gracefully stopping ...","Level":"info","Location":"main.go:116","Time":"2020-08-13 17:23:34.067751"}
clair_1          | {"Event":"main API stopped","Level":"info","Location":"api.go:74","Time":"2020-08-13 17:23:34.067879"}
clair_1          | {"Event":"health API stopped","Level":"info","Location":"api.go:98","Time":"2020-08-13 17:23:34.067920"}
clair_1          | {"Event":"updater service stopped","Level":"info","Location":"updater.go:161","Time":"2020-08-13 17:23:34.713615"}
18-19_absace_clair_1 exited with code 0
postgres_1       | LOG:  received smart shutdown request
postgres_1       | LOG:  autovacuum launcher shutting down
postgres_1       | LOG:  shutting down
postgres_1       | LOG:  database system is shut down
18-19_absace_postgres_1 exited with code 0
ubuntu@ip-172-31-41-31:~/18-19_absace$ docker-compose up
Starting 18-19_absace_sonarqube_1 ... done
Starting 18-19_absace_postgres_1  ... done
Starting 18-19_absace_jenkins_1   ... done
Starting 18-19_absace_clair_1     ... done
Starting 18-19_absace_clairctl_1     ... done
Creating 18-19_absace_clairscanner_1 ... done
Attaching to 18-19_absace_sonarqube_1, 18-19_absace_jenkins_1, 18-19_absace_postgres_1, 18-19_absace_clair_1, 18-19_absace_clairctl_1, 18-19_absace_clairscanner_1
clair_1         | {"Event":"running database migrations","Level":"info","Location":"pgsql.go:216","Time":"2020-08-13 17:24:32.528527"}
clair_1         | {"Event":"database migration ran successfully","Level":"info","Location":"pgsql.go:223","Time":"2020-08-13 17:24:32.543955"}
clair_1         | {"Event":"starting main API","Level":"info","Location":"api.go:52","Time":"2020-08-13 17:24:32.544262","port":6060}
clair_1         | {"Event":"notifier service is disabled","Level":"info","Location":"notifier.go:77","Time":"2020-08-13 17:24:32.544683"}
clair_1         | {"Event":"starting health API","Level":"info","Location":"api.go:85","Time":"2020-08-13 17:24:32.544839","port":6061}
clair_1         | {"Event":"updater service started","Level":"info","Location":"updater.go:81","Time":"2020-08-13 17:24:32.544989","lock identifier":"add237f9-1126-4006-9dc0-d626b25b7705"}
jenkins_1       | Running from: /usr/share/jenkins/jenkins.war
jenkins_1       | webroot: EnvVars.masterEnvVars.get("JENKINS_HOME")
jenkins_1       | 2020-08-13 17:24:31.240+0000 [id=1]   INFO    org.eclipse.jetty.util.log.Log#initialized: Logging initialized @395ms to org.eclipse.jetty.util.log.JavaUtilLog
jenkins_1       | 2020-08-13 17:24:31.406+0000 [id=1]   INFO    winstone.Logger#logInternal: Beginning extraction from war file
jenkins_1       | 2020-08-13 17:24:31.444+0000 [id=1]   WARNING o.e.j.s.handler.ContextHandler#setContextPath: Empty contextPath
jenkins_1       | 2020-08-13 17:24:31.515+0000 [id=1]   INFO    org.eclipse.jetty.server.Server#doStart: jetty-9.4.27.v20200227; built: 2020-02-27T18:37:21.340Z; git: a304fd9f351f337e7c0e2a7c28878dd536149c6c; jvm 1.8.0_242-b08
jenkins_1       | 2020-08-13 17:24:31.899+0000 [id=1]   INFO    o.e.j.w.StandardDescriptorProcessor#visitServlet: NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
jenkins_1       | 2020-08-13 17:24:31.981+0000 [id=1]   INFO    o.e.j.s.s.DefaultSessionIdManager#doStart: DefaultSessionIdManager workerName=node0
jenkins_1       | 2020-08-13 17:24:31.981+0000 [id=1]   INFO    o.e.j.s.s.DefaultSessionIdManager#doStart: No SessionScavenger set, using defaults
jenkins_1       | 2020-08-13 17:24:31.992+0000 [id=1]   INFO    o.e.j.server.session.HouseKeeper#startScavenging: node0 Scavenging every 660000ms
jenkins_1       | 2020-08-13 17:24:32.526+0000 [id=1]   INFO    hudson.WebAppMain#contextInitialized: Jenkins home directory: /var/jenkins_home found at: EnvVars.masterEnvVars.get("JENKINS_HOME")
jenkins_1       | 2020-08-13 17:24:32.702+0000 [id=1]   INFO    o.e.j.s.handler.ContextHandler#doStart: Started w.@4470fbd6{Jenkins v2.235.3,/,file:///var/jenkins_home/war/,AVAILABLE}{/var/jenkins_home/war}
jenkins_1       | 2020-08-13 17:24:32.766+0000 [id=1]   INFO    o.e.j.server.AbstractConnector#doStart: Started ServerConnector@5315b42e{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}
jenkins_1       | 2020-08-13 17:24:32.766+0000 [id=1]   INFO    org.eclipse.jetty.server.Server#doStart: Started @1922ms
jenkins_1       | 2020-08-13 17:24:32.782+0000 [id=21]  INFO    winstone.Logger#logInternal: Winstone Servlet Engine running: controlPort=disabled
postgres_1      |
postgres_1      | PostgreSQL Database directory appears to contain a database; Skipping initialization
postgres_1      |
postgres_1      | LOG:  database system was shut down at 2020-08-13 17:23:35 UTC
postgres_1      | LOG:  MultiXact member wraparound protections are now enabled
postgres_1      | LOG:  database system is ready to accept connections
postgres_1      | LOG:  autovacuum launcher started
sonarqube_1     | 2020.08.13 17:12:58 WARN  es[][o.e.b.BootstrapChecks] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
sonarqube_1     | 2020.08.13 17:13:01 INFO  es[][o.e.c.s.MasterService] zen-disco-elected-as-master ([0] nodes joined), reason: new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{9hJXHFmeQEKQe2mixYY3rQ}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}
sonarqube_1     | 2020.08.13 17:13:01 INFO  es[][o.e.c.s.ClusterApplierService] new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{9hJXHFmeQEKQe2mixYY3rQ}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}, reason: apply cluster state (from master [master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{9hJXHFmeQEKQe2mixYY3rQ}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube} committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])
sonarqube_1     | 2020.08.13 17:13:01 INFO  es[][o.e.n.Node] started
sonarqube_1     | 2020.08.13 17:13:02 INFO  es[][o.e.g.GatewayService] recovered [7] indices into cluster_state
sonarqube_1     | 2020.08.13 17:13:03 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[metadatas][0]] ...]).
sonarqube_1     | 2020.08.13 17:23:24 INFO  es[][o.e.n.Node] stopping ...
sonarqube_1     | 2020.08.13 17:23:24 INFO  es[][o.e.n.Node] stopped
sonarqube_1     | 2020.08.13 17:23:24 INFO  es[][o.e.n.Node] closing ...
sonarqube_1     | 2020.08.13 17:23:24 INFO  es[][o.e.n.Node] closed
sonarqube_1     | 2020.08.13 17:24:31 INFO  app[][o.s.a.AppFileSystem] Cleaning or creating temp directory /opt/sonarqube/temp
sonarqube_1     | 2020.08.13 17:24:31 INFO  app[][o.s.a.es.EsSettings] Elasticsearch listening on /127.0.0.1:9001
sonarqube_1     | 2020.08.13 17:24:31 INFO  app[][o.s.a.ProcessLauncherImpl] Launch process[[key='es', ipcIndex=1, logFilenamePrefix=es]] from [/opt/sonarqube/elasticsearch]: /opt/sonarqube/elasticsearch/bin/elasticsearch
sonarqube_1     | 2020.08.13 17:24:31 INFO  app[][o.s.a.SchedulerImpl] Waiting for Elasticsearch to be up and running
sonarqube_1     | 2020.08.13 17:24:32 INFO  app[][o.e.p.PluginsService] no modules loaded
sonarqube_1     | 2020.08.13 17:24:32 INFO  app[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
sonarqube_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
jenkins_1       | 2020-08-13 17:24:34.565+0000 [id=27]  INFO    jenkins.InitReactorRunner$1#onAttained: Started initialization
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 17:24:35.081+0000 [id=28]  INFO    jenkins.InitReactorRunner$1#onAttained: Listed all plugins
18-19_absace_clairscanner_1 exited with code 0
sonarqube_1     | 2020.08.13 17:24:35 INFO  es[][o.e.e.NodeEnvironment] using [1] data paths, mounts [[/opt/sonarqube/data (/dev/xvda1)]], net usable_space [15.1gb], net total_space [29gb], types [ext4]
sonarqube_1     | 2020.08.13 17:24:35 INFO  es[][o.e.e.NodeEnvironment] heap size [494.9mb], compressed ordinary object pointers [true]
sonarqube_1     | 2020.08.13 17:24:35 INFO  es[][o.e.n.Node] node name [sonarqube], node ID [OspwetY9T2i0OWqdt0vgOg]
sonarqube_1     | 2020.08.13 17:24:35 INFO  es[][o.e.n.Node] version[6.8.0], pid[30], build[default/tar/65b6179/2019-05-15T20:06:13.172855Z], OS[Linux/5.3.0-1032-aws/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/11.0.8/11.0.8+10]
sonarqube_1     | 2020.08.13 17:24:35 INFO  es[][o.e.n.Node] JVM arguments [-XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=/opt/sonarqube/temp, -XX:ErrorFile=../logs/es_hs_err_pid%p.log, -Xms512m, -Xmx512m, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/opt/sonarqube/elasticsearch, -Des.path.conf=/opt/sonarqube/temp/conf/es, -Des.distribution.flavor=default, -Des.distribution.type=tar]
18-19_absace_clairscanner_1 exited with code 0
sonarqube_1     | 2020.08.13 17:24:36 INFO  es[][o.e.p.PluginsService] loaded module [analysis-common]
sonarqube_1     | 2020.08.13 17:24:36 INFO  es[][o.e.p.PluginsService] loaded module [lang-painless]
sonarqube_1     | 2020.08.13 17:24:36 INFO  es[][o.e.p.PluginsService] loaded module [mapper-extras]
sonarqube_1     | 2020.08.13 17:24:36 INFO  es[][o.e.p.PluginsService] loaded module [parent-join]
sonarqube_1     | 2020.08.13 17:24:36 INFO  es[][o.e.p.PluginsService] loaded module [percolator]
sonarqube_1     | 2020.08.13 17:24:36 INFO  es[][o.e.p.PluginsService] loaded module [reindex]
sonarqube_1     | 2020.08.13 17:24:36 INFO  es[][o.e.p.PluginsService] loaded module [repository-url]
sonarqube_1     | 2020.08.13 17:24:36 INFO  es[][o.e.p.PluginsService] loaded module [transport-netty4]
sonarqube_1     | 2020.08.13 17:24:36 INFO  es[][o.e.p.PluginsService] no plugins loaded
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
sonarqube_1     | 2020.08.13 17:24:39 WARN  es[][o.e.d.c.s.Settings] [http.enabled] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version.
sonarqube_1     | 2020.08.13 17:24:40 INFO  es[][o.e.d.DiscoveryModule] using discovery type [zen] and host providers [settings]
sonarqube_1     | 2020.08.13 17:24:41 INFO  es[][o.e.n.Node] initialized
sonarqube_1     | 2020.08.13 17:24:41 INFO  es[][o.e.n.Node] starting ...
sonarqube_1     | 2020.08.13 17:24:41 INFO  es[][o.e.t.TransportService] publish_address {127.0.0.1:9001}, bound_addresses {127.0.0.1:9001}
sonarqube_1     | 2020.08.13 17:24:41 WARN  es[][o.e.b.BootstrapChecks] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
jenkins_1       | 2020-08-13 17:24:43.909+0000 [id=26]  INFO    jenkins.InitReactorRunner$1#onAttained: Prepared all plugins
jenkins_1       | 2020-08-13 17:24:43.922+0000 [id=27]  INFO    jenkins.InitReactorRunner$1#onAttained: Started all plugins
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 17:24:45.480+0000 [id=32]  WARNING o.j.p.d.DockerBuilder$DescriptorImpl#<init>: Docker URL is not set, docker client won't be initialized
jenkins_1       | 2020-08-13 17:24:45.670+0000 [id=28]  INFO    jenkins.InitReactorRunner$1#onAttained: Augmented all extensions
jenkins_1       | 2020-08-13 17:24:45.773+0000 [id=27]  INFO    jenkins.InitReactorRunner$1#onAttained: System config loaded
jenkins_1       | 2020-08-13 17:24:45.808+0000 [id=30]  INFO    jenkins.InitReactorRunner$1#onAttained: System config adapted
sonarqube_1     | 2020.08.13 17:24:45 INFO  es[][o.e.c.s.MasterService] zen-disco-elected-as-master ([0] nodes joined), reason: new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{V3Ak6ILsSkeZOaDZxVFUYg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}
sonarqube_1     | 2020.08.13 17:24:45 INFO  es[][o.e.c.s.ClusterApplierService] new_master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{V3Ak6ILsSkeZOaDZxVFUYg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube}, reason: apply cluster state (from master [master {sonarqube}{OspwetY9T2i0OWqdt0vgOg}{V3Ak6ILsSkeZOaDZxVFUYg}{127.0.0.1}{127.0.0.1:9001}{rack_id=sonarqube} committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])
sonarqube_1     | 2020.08.13 17:24:45 INFO  es[][o.e.n.Node] started
sonarqube_1     | 2020.08.13 17:24:45 INFO  es[][o.e.g.GatewayService] recovered [7] indices into cluster_state
jenkins_1       | 2020-08-13 17:24:45.944+0000 [id=32]  INFO    jenkins.InitReactorRunner$1#onAttained: Loaded all jobs
jenkins_1       | 2020-08-13 17:24:45.949+0000 [id=29]  INFO    jenkins.InitReactorRunner$1#onAttained: Configuration for all jobs updated
jenkins_1       | 2020-08-13 17:24:46.035+0000 [id=46]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started Download metadata
jenkins_1       | 2020-08-13 17:24:46.058+0000 [id=46]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished Download metadata. 11 ms
jenkins_1       | 2020-08-13 17:24:46.587+0000 [id=31]  INFO    o.s.c.s.AbstractApplicationContext#prepareRefresh: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@17594338: display name [Root WebApplicationContext]; startup date [Thu Aug 13 17:24:46 UTC 2020]; root of context hierarchy
jenkins_1       | 2020-08-13 17:24:46.587+0000 [id=31]  INFO    o.s.c.s.AbstractApplicationContext#obtainFreshBeanFactory: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@17594338]: org.springframework.beans.factory.support.DefaultListableBeanFactory@2020bf09
jenkins_1       | 2020-08-13 17:24:46.618+0000 [id=31]  INFO    o.s.b.f.s.DefaultListableBeanFactory#preInstantiateSingletons: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@2020bf09: defining beans [authenticationManager]; root of factory hierarchy
jenkins_1       | 2020-08-13 17:24:46.855+0000 [id=31]  INFO    o.s.c.s.AbstractApplicationContext#prepareRefresh: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@3c086540: display name [Root WebApplicationContext]; startup date [Thu Aug 13 17:24:46 UTC 2020]; root of context hierarchy
jenkins_1       | 2020-08-13 17:24:46.855+0000 [id=31]  INFO    o.s.c.s.AbstractApplicationContext#obtainFreshBeanFactory: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@3c086540]: org.springframework.beans.factory.support.DefaultListableBeanFactory@6c44e062
jenkins_1       | 2020-08-13 17:24:46.855+0000 [id=31]  INFO    o.s.b.f.s.DefaultListableBeanFactory#preInstantiateSingletons: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@6c44e062: defining beans [filter,legacy]; root of factory hierarchy
jenkins_1       | 2020-08-13 17:24:46.916+0000 [id=31]  INFO    jenkins.InitReactorRunner$1#onAttained: Completed initialization
jenkins_1       | 2020-08-13 17:24:47.057+0000 [id=20]  INFO    hudson.WebAppMain$3#run: Jenkins is fully up and running
sonarqube_1     | 2020.08.13 17:24:47 INFO  app[][o.s.a.SchedulerImpl] Process[es] is up
sonarqube_1     | 2020.08.13 17:24:47 INFO  app[][o.s.a.ProcessLauncherImpl] Launch process[[key='web', ipcIndex=2, logFilenamePrefix=web]] from [/opt/sonarqube]: /usr/local/openjdk-11/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/opt/sonarqube/temp --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.rmi/sun.rmi.transport=ALL-UNNAMED -Xmx512m -Xms128m -XX:+HeapDumpOnOutOfMemoryError -Djava.security.egd=file:/dev/./urandom -Dhttp.nonProxyHosts=localhost|127.*|[::1] -cp ./lib/common/*:/opt/sonarqube/lib/jdbc/h2/h2-1.3.176.jar org.sonar.server.app.WebServer /opt/sonarqube/temp/sq-process10373488096401370848properties
sonarqube_1     | 2020.08.13 17:24:47 INFO  web[][o.s.p.ProcessEntryPoint] Starting web
sonarqube_1     | 2020.08.13 17:24:47 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[components][4], [components][0]] ...]).
sonarqube_1     | 2020.08.13 17:24:48 INFO  web[][o.a.t.u.n.NioSelectorPool] Using a shared selector for servlet write/read
sonarqube_1     | 2020.08.13 17:24:48 INFO  web[][o.e.p.PluginsService] no modules loaded
sonarqube_1     | 2020.08.13 17:24:48 INFO  web[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.join.ParentJoinPlugin]
sonarqube_1     | 2020.08.13 17:24:48 INFO  web[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
sonarqube_1     | 2020.08.13 17:24:48 INFO  web[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
sonarqube_1     | 2020.08.13 17:24:50 INFO  web[][o.s.s.e.EsClientProvider] Connected to local Elasticsearch: [127.0.0.1:9001]
sonarqube_1     | 2020.08.13 17:24:50 INFO  web[][o.s.s.p.LogServerVersion] SonarQube Server / 7.9.4.35981 / 0a370ee33e97c5d5e3a038a3f7dc4c0162319835
sonarqube_1     | 2020.08.13 17:24:50 INFO  web[][o.s.s.p.d.EmbeddedDatabase] Starting embedded database on port 9092 with url jdbc:h2:tcp://127.0.0.1:9092/sonar
sonarqube_1     | 2020.08.13 17:24:50 INFO  web[][o.s.s.p.d.EmbeddedDatabase] Embedded database started. Data stored in: /opt/sonarqube/data
sonarqube_1     | 2020.08.13 17:24:50 INFO  web[][o.sonar.db.Database] Create JDBC data source for jdbc:h2:tcp://127.0.0.1:9092/sonar
sonarqube_1     | 2020.08.13 17:24:50 WARN  web[][o.s.db.dialect.H2] H2 database should be used for evaluation purpose only.
18-19_absace_clairscanner_1 exited with code 0
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerFileSystemImpl] SonarQube home: /opt/sonarqube
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.u.SystemPasscodeImpl] System authentication by passcode is disabled
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin Git / 1.8.0.1574 / aec3dc8f5228aabd218e1cd31ac6e6515a43715d
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin GitHub Authentication for SonarQube / 1.5.0.870 / 153f7c7af7a264adb0fcbe5fee87bdd140a6a3a1
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin JaCoCo / 1.0.2.475 / b79a4724f3a9af1051266b4f8ca0460977295ead
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin LDAP / 2.2.0.608 / 79dc3fa4393a29667673c70182f3016288b548b7
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SAML 2.0 Authentication for SonarQube / 1.2.0.682 / 44d64e660a3c7f235962a7bcfef78bf8c87db98a
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarC# / 7.15.0.8572 / e0ad49e38a28a8fc333ba746fc998e48678f6a8b
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarCSS / 1.1.1.1010 / 365e21fd0cb9035669fc59f6fec7c8fd28a7303b
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarFlex / 2.5.1.1831 / a0c44437f6abb0feec76edd073f91fec64db2a6c
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarGo / 1.1.1.2000 / 40d55921c7a63b67386a053490d17b6723a46cd5
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarHTML / 3.1.0.1615 / 4181edb5eff5605bec82dc0aa15ecd70eaa5857f
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarJS / 5.2.1.7778 / 49f34eaeaad59868d4353d89b1fc5c02bbe51976
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarJava / 5.13.1.18282 / 568f8ed2349f48e250a9329895b9a870100dfbeb
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarKotlin / 1.5.0.315 / 4ff3a145a58f3f84f1b39846a205a129d742e993
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarPHP / 3.2.0.4868 / ec66bd5f8490677eb0ebae82aa17c2a5d9c0e5e7
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarPython / 1.14.1.3143 / eed7b315b6116fe462a19c771013bf3891c92a97
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarRuby / 1.5.0.315 / 4ff3a145a58f3f84f1b39846a205a129d742e993
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarScala / 1.5.0.315 / 4ff3a145a58f3f84f1b39846a205a129d742e993
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarTS / 1.9.0.3766 / 4a4080b78001a78d758d1d0fa0190fb9496b6f57
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarVB / 7.15.0.8572 / e0ad49e38a28a8fc333ba746fc998e48678f6a8b
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin SonarXML / 2.0.1.2020 / c5b84004face582d56f110e24c29bf9c6a679e69
sonarqube_1     | 2020.08.13 17:24:51 INFO  web[][o.s.s.p.ServerPluginRepository] Deploy plugin Svn / 1.9.0.1295 / 942e075773975354e32691a60bfd968065703e04
sonarqube_1     | 2020.08.13 17:24:52 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.WebServiceFilter@4f330e39 [pattern=UrlPattern{inclusions=[/api/system/migrate_db.*, ...], exclusions=[/api/properties*, ...]}]
sonarqube_1     | 2020.08.13 17:24:52 INFO  web[][o.s.s.a.EmbeddedTomcat] HTTP connector enabled on port 9000
sonarqube_1     | 2020.08.13 17:24:53 INFO  web[][o.s.s.p.UpdateCenterClient] Update center: https://update.sonarsource.org/update-center.properties (no proxy)
sonarqube_1     | 2020.08.13 17:24:54 INFO  web[][o.s.s.s.LogServerId] Server ID: BF41A1F2-AXOwq_Q3V0p2MHt8HbhA
sonarqube_1     | 2020.08.13 17:24:54 WARN  web[][o.s.s.a.LogOAuthWarning] For security reasons, OAuth authentication should use HTTPS. You should set the property 'Administration > Configuration > Server base URL' to a HTTPS URL.
sonarqube_1     | 2020.08.13 17:24:54 WARN  web[][o.s.a.s.w.WebService$Action] The response example is not set on action api/plugins/download
sonarqube_1     | 2020.08.13 17:24:54 WARN  web[][o.s.a.s.w.WebService$Action] The response example is not set on action api/permissions/search_templates
sonarqube_1     | 2020.08.13 17:24:54 INFO  web[][o.s.s.t.TelemetryDaemon] Sharing of SonarQube statistics is enabled.
sonarqube_1     | 2020.08.13 17:24:54 INFO  web[][o.s.s.n.NotificationDaemon] Notification service started (delay 60 sec.)
sonarqube_1     | 2020.08.13 17:24:54 INFO  web[][o.s.s.s.GeneratePluginIndex] Generate scanner plugin index
sonarqube_1     | 2020.08.13 17:24:54 INFO  web[][o.s.s.s.RegisterPlugins] Register plugins
sonarqube_1     | 2020.08.13 17:24:54 INFO  web[][o.s.s.s.RegisterMetrics] Register metrics
sonarqube_1     | 2020.08.13 17:24:54 INFO  web[][o.s.s.r.RegisterRules] Register rules
sonarqube_1     | 2020.08.13 17:25:00 INFO  web[][o.s.s.q.BuiltInQProfileRepositoryImpl] Load quality profiles
sonarqube_1     | 2020.08.13 17:25:01 INFO  web[][o.s.s.q.RegisterQualityProfiles] Register quality profiles
sonarqube_1     | 2020.08.13 17:25:01 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile css/Sonar way
sonarqube_1     | 2020.08.13 17:25:01 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile scala/Sonar way
sonarqube_1     | 2020.08.13 17:25:01 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile jsp/Sonar way
sonarqube_1     | 2020.08.13 17:25:01 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile go/Sonar way
sonarqube_1     | 2020.08.13 17:25:01 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile kotlin/Sonar way
sonarqube_1     | 2020.08.13 17:25:01 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile js/Sonar way Recommended
sonarqube_1     | 2020.08.13 17:25:02 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile js/Sonar way
sonarqube_1     | 2020.08.13 17:25:02 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile py/Sonar way
sonarqube_1     | 2020.08.13 17:25:02 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile ruby/Sonar way
sonarqube_1     | 2020.08.13 17:25:02 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile cs/Sonar way
sonarqube_1     | 2020.08.13 17:25:02 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile java/Sonar way
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile web/Sonar way
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile flex/Sonar way
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile xml/Sonar way
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile php/Sonar way
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile php/PSR-2
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile php/Drupal
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile vbnet/Sonar way
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile ts/Sonar way
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.q.RegisterQualityProfiles] Update profile ts/Sonar way recommended
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.s.RegisterPermissionTemplates] Register permission templates
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.s.RenameDeprecatedPropertyKeys] Rename deprecated property keys
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.WebServiceFilter@1cd6e897 [pattern=UrlPattern{inclusions=[/api/issues/delete_comment.*, ...], exclusions=[/api/properties*, ...]}]
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.DeprecatedPropertiesWsFilter@75a614b [pattern=UrlPattern{inclusions=[/api/properties/*], exclusions=[]}]
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.ws.WebServiceReroutingFilter@165a562 [pattern=UrlPattern{inclusions=[/api/components/bulk_update_key, ...], exclusions=[]}]
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.InitFilter@51053789 [pattern=UrlPattern{inclusions=[/sessions/init/*], exclusions=[]}]
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.OAuth2CallbackFilter@1c0fc26a [pattern=UrlPattern{inclusions=[/oauth2/callback/*], exclusions=[]}]
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.ws.LoginAction@3f9533f7 [pattern=UrlPattern{inclusions=[/api/authentication/login], exclusions=[]}]
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.ws.LogoutAction@4a219a9 [pattern=UrlPattern{inclusions=[/api/authentication/logout], exclusions=[]}]
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.p.w.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.ws.ValidateAction@72659a90 [pattern=UrlPattern{inclusions=[/api/authentication/validate], exclusions=[]}]
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.q.ProjectsInWarningDaemon] Counting number of projects in warning is not started as there are no projects in this situation.
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.p.p.PlatformLevelStartup] Running Community Edition
sonarqube_1     | 2020.08.13 17:25:03 INFO  web[][o.s.s.p.Platform] WebServer is operational
sonarqube_1     | 2020.08.13 17:25:04 INFO  app[][o.s.a.SchedulerImpl] Process[web] is up
sonarqube_1     | 2020.08.13 17:25:04 INFO  app[][o.s.a.ProcessLauncherImpl] Launch process[[key='ce', ipcIndex=3, logFilenamePrefix=ce]] from [/opt/sonarqube]: /usr/local/openjdk-11/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/opt/sonarqube/temp --add-opens=java.base/java.util=ALL-UNNAMED -Xmx512m -Xms128m -XX:+HeapDumpOnOutOfMemoryError -Dhttp.nonProxyHosts=localhost|127.*|[::1] -cp ./lib/common/*:/opt/sonarqube/lib/jdbc/h2/h2-1.3.176.jar org.sonar.ce.app.CeServer /opt/sonarqube/temp/sq-process3158392718335669621properties
18-19_absace_clairscanner_1 exited with code 0
sonarqube_1     | 2020.08.13 17:25:04 INFO  ce[][o.s.p.ProcessEntryPoint] Starting ce
sonarqube_1     | 2020.08.13 17:25:04 INFO  ce[][o.s.ce.app.CeServer] Compute Engine starting up...
sonarqube_1     | 2020.08.13 17:25:05 INFO  ce[][o.e.p.PluginsService] no modules loaded
sonarqube_1     | 2020.08.13 17:25:05 INFO  ce[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.join.ParentJoinPlugin]
sonarqube_1     | 2020.08.13 17:25:05 INFO  ce[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
sonarqube_1     | 2020.08.13 17:25:05 INFO  ce[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
sonarqube_1     | 2020.08.13 17:25:06 INFO  ce[][o.s.s.e.EsClientProvider] Connected to local Elasticsearch: [127.0.0.1:9001]
sonarqube_1     | 2020.08.13 17:25:06 INFO  ce[][o.sonar.db.Database] Create JDBC data source for jdbc:h2:tcp://127.0.0.1:9092/sonar
sonarqube_1     | 2020.08.13 17:25:06 WARN  ce[][o.s.db.dialect.H2] H2 database should be used for evaluation purpose only.
sonarqube_1     | 2020.08.13 17:25:07 INFO  ce[][o.s.s.p.ServerFileSystemImpl] SonarQube home: /opt/sonarqube
sonarqube_1     | 2020.08.13 17:25:07 INFO  ce[][o.s.c.c.CePluginRepository] Load plugins
sonarqube_1     | 2020.08.13 17:25:08 INFO  ce[][o.s.c.c.ComputeEngineContainerImpl] Running Community edition
sonarqube_1     | 2020.08.13 17:25:08 INFO  ce[][o.s.ce.app.CeServer] Compute Engine is operational
sonarqube_1     | 2020.08.13 17:25:08 INFO  app[][o.s.a.SchedulerImpl] Process[ce] is up
sonarqube_1     | 2020.08.13 17:25:08 INFO  app[][o.s.a.SchedulerImpl] SonarQube is up
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 17:25:37.254+0000 [id=63]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 17:25:37.255+0000 [id=63]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 17:25:37.257+0000 [id=63]  INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 0, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 17:25:37.258+0000 [id=63]  INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 17:25:37.258+0000 [id=63]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 17:25:37.258+0000 [id=63]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 4 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 17:30:37.254+0000 [id=64]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 17:30:37.254+0000 [id=64]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 17:30:37.255+0000 [id=64]  INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 1, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 1 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 17:30:37.255+0000 [id=64]  INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 17:30:37.255+0000 [id=64]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 17:30:37.255+0000 [id=64]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 17:35:37.254+0000 [id=65]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 17:35:37.254+0000 [id=65]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 17:35:37.255+0000 [id=65]  INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 2, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 17:35:37.255+0000 [id=65]  INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 17:35:37.255+0000 [id=65]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 17:35:37.255+0000 [id=65]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 17:38:49.709+0000 [id=66]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started Periodic background build discarder
jenkins_1       | 2020-08-13 17:38:49.714+0000 [id=66]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished Periodic background build discarder. 3 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 17:40:37.254+0000 [id=67]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 17:40:37.255+0000 [id=67]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 17:40:37.255+0000 [id=67]  INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 3, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 17:40:37.255+0000 [id=67]  INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 17:40:37.255+0000 [id=67]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 17:40:37.255+0000 [id=67]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 17:43:54.297+0000 [id=13]  INFO    o.j.p.p.m.GlobalPipelineMavenConfig#getDao: Connect to database jdbc:h2:file:/var/jenkins_home/jenkins-jobs/jenkins-jobs;AUTO_SERVER=TRUE;MULTI_THREADED=1;QUERY_CACHE_SIZE=25;JMX=TRUE with username sa and properties {}
jenkins_1       | 2020-08-13 17:43:54.309+0000 [id=13]  INFO    c.zaxxer.hikari.HikariDataSource#<init>: HikariPool-1 - Starting...
jenkins_1       | 2020-08-13 17:43:55.469+0000 [id=13]  INFO    c.zaxxer.hikari.HikariDataSource#<init>: HikariPool-1 - Start completed.
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 17:45:37.254+0000 [id=80]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 17:45:37.255+0000 [id=80]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 17:45:37.255+0000 [id=80]  INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 4, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 17:45:37.255+0000 [id=80]  INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 17:45:37.255+0000 [id=80]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 17:45:37.255+0000 [id=80]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 17:50:37.254+0000 [id=90]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 17:50:37.254+0000 [id=90]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 17:50:37.255+0000 [id=90]  INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 5, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 17:50:37.255+0000 [id=90]  INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 17:50:37.255+0000 [id=90]  INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 17:50:37.255+0000 [id=90]  INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
jenkins_1       | 2020-08-13 17:50:43.412+0000 [id=97]  INFO    o.j.p.workflow.job.WorkflowRun#finish: EnvironmentTesting #17 completed: FAILURE
jenkins_1       | 2020-08-13 17:50:43.447+0000 [id=97]  INFO    o.j.p.p.m.d.AbstractPipelineMavenPluginDao#getJenkinsMasterPrimaryKey: Update url from "http://34.245.15.238:8080/" to "http://34.245.80.13:8080/" for master with legacyId 07056d5606b71780ce4c861a3ae75c18
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 17:55:37.254+0000 [id=107] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 17:55:37.254+0000 [id=107] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 17:55:37.255+0000 [id=107] INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 6, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 17:55:37.255+0000 [id=107] INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 17:55:37.255+0000 [id=107] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 17:55:37.255+0000 [id=107] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 18:00:37.254+0000 [id=108] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 18:00:37.254+0000 [id=108] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 18:00:37.254+0000 [id=108] INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 7, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 18:00:37.255+0000 [id=108] INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 18:00:37.255+0000 [id=108] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 18:00:37.255+0000 [id=108] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 18:05:37.254+0000 [id=109] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 18:05:37.254+0000 [id=109] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 18:05:37.255+0000 [id=109] INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 8, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 18:05:37.255+0000 [id=109] INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 18:05:37.255+0000 [id=109] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 18:05:37.255+0000 [id=109] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 18:10:37.254+0000 [id=113] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 18:10:37.255+0000 [id=113] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 18:10:37.255+0000 [id=113] INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 9, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 18:10:37.255+0000 [id=113] INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 18:10:37.255+0000 [id=113] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 18:10:37.255+0000 [id=113] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 18:11:26.565+0000 [id=119] INFO    o.j.p.workflow.job.WorkflowRun#finish: EnvironmentTesting #18 completed: FAILURE
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 18:13:36.306+0000 [id=170] INFO    o.j.p.workflow.job.WorkflowRun#finish: EnvironmentTesting #19 completed: SUCCESS
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 18:15:37.254+0000 [id=174] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 18:15:37.254+0000 [id=174] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 18:15:37.255+0000 [id=174] INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 10, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 18:15:37.255+0000 [id=174] INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 18:15:37.255+0000 [id=174] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 18:15:37.255+0000 [id=174] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 18:17:10.209+0000 [id=182] INFO    o.j.p.workflow.job.WorkflowRun#finish: EnvironmentTesting #20 completed: FAILURE
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 18:17:53.864+0000 [id=181] INFO    o.j.p.workflow.job.WorkflowRun#finish: EnvironmentTesting #21 completed: SUCCESS
18-19_absace_clairscanner_1 exited with code 0
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:19:02.837985","elapsed time":5264145,"method":"POST","remote addr":"172.18.0.4:51520","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:19:02.840722","elapsed time":1478543,"method":"POST","remote addr":"172.18.0.4:51522","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:19:02.843843","elapsed time":2080393,"method":"POST","remote addr":"172.18.0.4:51524","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:19:02.846675","elapsed time":1294823,"method":"POST","remote addr":"172.18.0.4:51526","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:19:02.849926","elapsed time":1200128,"method":"POST","remote addr":"172.18.0.4:51528","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:19:02.852931","elapsed time":1910709,"method":"POST","remote addr":"172.18.0.4:51530","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:19:02.854830","elapsed time":936542,"method":"POST","remote addr":"172.18.0.4:51532","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:19:02.856605","elapsed time":828469,"method":"POST","remote addr":"172.18.0.4:51534","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:19:02.858850","elapsed time":1259927,"method":"POST","remote addr":"172.18.0.4:51536","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:19:02.980386","elapsed time":120594791,"method":"GET","remote addr":"172.18.0.4:51538","request uri":"/v1/layers/2192b11f1bc92ed11d768ed116c5944fe47e2944a521cf2f98ca10fce794841e?vulnerabilities","status":"200"}
jenkins_1       | 2020-08-13 18:19:03.543+0000 [id=242] INFO    o.j.p.workflow.job.WorkflowRun#finish: EnvironmentTesting #22 completed: SUCCESS
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 18:20:37.254+0000 [id=247] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 18:20:37.254+0000 [id=247] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 18:20:37.255+0000 [id=247] INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 11, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 18:20:37.255+0000 [id=247] INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 18:20:37.255+0000 [id=247] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 18:20:37.255+0000 [id=247] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 18:22:34.557+0000 [id=257] INFO    o.j.p.workflow.job.WorkflowRun#finish: WebGoat_Pipeline #35 completed: FAILURE
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
sonarqube_1     | 2020.08.13 18:24:27 INFO  ce[][o.s.c.t.CeWorkerImpl] Execute task | project=webgoat | type=REPORT | id=AXPpEOaVlmU9fRNBTMKj
sonarqube_1     | 2020.08.13 18:24:28 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Extract report | status=SUCCESS | time=629ms
sonarqube_1     | 2020.08.13 18:24:28 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist scanner context | status=SUCCESS | time=11ms
sonarqube_1     | 2020.08.13 18:24:28 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Propagate analysis warnings from scanner report | status=SUCCESS | time=27ms
sonarqube_1     | 2020.08.13 18:24:28 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Execute DB migrations for current project | status=SUCCESS | time=9ms
sonarqube_1     | 2020.08.13 18:24:28 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Generate analysis UUID | status=SUCCESS | time=0ms
sonarqube_1     | 2020.08.13 18:24:28 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Load analysis metadata | status=SUCCESS | time=113ms
sonarqube_1     | 2020.08.13 18:24:28 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Initialize | status=SUCCESS | time=0ms
sonarqube_1     | 2020.08.13 18:24:28 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Verify billing | status=SUCCESS | time=0ms
sonarqube_1     | 2020.08.13 18:24:29 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Build tree of components | components=903 | status=SUCCESS | time=548ms
sonarqube_1     | 2020.08.13 18:24:29 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Validate project | status=SUCCESS | time=18ms
sonarqube_1     | 2020.08.13 18:24:30 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Load quality profiles | status=SUCCESS | time=1433ms
sonarqube_1     | 2020.08.13 18:24:30 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Load Quality gate | status=SUCCESS | time=32ms
sonarqube_1     | 2020.08.13 18:24:30 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Load new code period | status=SUCCESS | time=10ms
sonarqube_1     | 2020.08.13 18:24:31 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Detect file moves | reportFiles=595 | dbFiles=595 | addedFiles=0 | status=SUCCESS | time=286ms
sonarqube_1     | 2020.08.13 18:24:31 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Load duplications | duplications=75 | status=SUCCESS | time=32ms
sonarqube_1     | 2020.08.13 18:24:31 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute cross project duplications | status=SUCCESS | time=0ms
sonarqube_1     | 2020.08.13 18:24:31 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute size measures | status=SUCCESS | time=130ms
sonarqube_1     | 2020.08.13 18:24:34 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute new coverage | status=SUCCESS | time=3466ms
sonarqube_1     | 2020.08.13 18:24:34 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute coverage measures | status=SUCCESS | time=114ms
sonarqube_1     | 2020.08.13 18:24:34 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute comment measures | status=SUCCESS | time=11ms
sonarqube_1     | 2020.08.13 18:24:34 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Copy custom measures | status=SUCCESS | time=3ms
sonarqube_1     | 2020.08.13 18:24:34 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute duplication measures | status=SUCCESS | time=15ms
sonarqube_1     | 2020.08.13 18:24:34 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute size measures on new code | status=SUCCESS | time=34ms
sonarqube_1     | 2020.08.13 18:24:34 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute language distribution | status=SUCCESS | time=35ms
sonarqube_1     | 2020.08.13 18:24:34 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute test measures | status=SUCCESS | time=10ms
sonarqube_1     | 2020.08.13 18:24:34 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute complexity measures | status=SUCCESS | time=12ms
sonarqube_1     | 2020.08.13 18:24:34 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Load measure computers | status=SUCCESS | time=2ms
sonarqube_1     | 2020.08.13 18:24:35 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute Quality Profile status | status=SUCCESS | time=93ms
sonarqube_1     | 2020.08.13 18:24:40 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Execute component visitors | status=SUCCESS | time=5590ms
sonarqube_1     | 2020.08.13 18:24:40 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Checks executed after computation of measures | status=SUCCESS | time=1ms
sonarqube_1     | 2020.08.13 18:24:40 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute Quality Gate measures | status=SUCCESS | time=59ms
sonarqube_1     | 2020.08.13 18:24:40 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Compute Quality profile measures | status=SUCCESS | time=6ms
sonarqube_1     | 2020.08.13 18:24:40 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Generate Quality profile events | status=SUCCESS | time=11ms
sonarqube_1     | 2020.08.13 18:24:40 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Generate Quality gate events | status=SUCCESS | time=1ms
sonarqube_1     | 2020.08.13 18:24:41 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist components | status=SUCCESS | time=254ms
sonarqube_1     | 2020.08.13 18:24:41 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist analysis | status=SUCCESS | time=5ms
sonarqube_1     | 2020.08.13 18:24:41 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist analysis properties | status=SUCCESS | time=1ms
sonarqube_1     | 2020.08.13 18:24:41 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist measures | inserts=75 | status=SUCCESS | time=51ms
18-19_absace_clairscanner_1 exited with code 0
sonarqube_1     | 2020.08.13 18:24:48 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist live measures | insertsOrUpdates=38833 | status=SUCCESS | time=7445ms
sonarqube_1     | 2020.08.13 18:24:48 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist duplication data | insertsOrUpdates=0 | status=SUCCESS | time=29ms
sonarqube_1     | 2020.08.13 18:24:48 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist new ad hoc Rules | status=SUCCESS | time=0ms
sonarqube_1     | 2020.08.13 18:24:50 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist issues | inserts=41 | updates=126 | merged=0 | untouched=2141 | status=SUCCESS | time=1873ms
sonarqube_1     | 2020.08.13 18:24:50 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist project links | status=SUCCESS | time=3ms
sonarqube_1     | 2020.08.13 18:24:50 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist events | status=SUCCESS | time=5ms
sonarqube_1     | 2020.08.13 18:24:55 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist sources | status=SUCCESS | time=4751ms
sonarqube_1     | 2020.08.13 18:24:55 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Persist cross project duplications | status=SUCCESS | time=0ms
sonarqube_1     | 2020.08.13 18:24:55 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Enable analysis | status=SUCCESS | time=8ms
sonarqube_1     | 2020.08.13 18:24:55 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Update last usage date of quality profiles | status=SUCCESS | time=36ms
sonarqube_1     | 2020.08.13 18:24:55 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Purge db | status=SUCCESS | time=449ms
sonarqube_1     | 2020.08.13 18:24:59 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Index analysis | status=SUCCESS | time=3798ms
sonarqube_1     | 2020.08.13 18:24:59 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Send issue notifications | newIssuesNotifs=0 | newIssuesDeliveries=0 | myNewIssuesNotifs=0 | myNewIssuesDeliveries=0 | changesNotifs=0 | changesDeliveries=0 | status=SUCCESS | time=4ms
sonarqube_1     | 2020.08.13 18:24:59 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Publish task results | status=SUCCESS | time=0ms
sonarqube_1     | 2020.08.13 18:24:59 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.s.ComputationStepExecutor] Trigger refresh of Portfolios and Applications | status=SUCCESS | time=0ms
sonarqube_1     | 2020.08.13 18:24:59 INFO  ce[AXPpEOaVlmU9fRNBTMKj][o.s.c.t.CeWorkerImpl] Executed task | project=webgoat | type=REPORT | id=AXPpEOaVlmU9fRNBTMKj | status=SUCCESS | time=32582ms
jenkins_1       | 2020-08-13 18:25:37.254+0000 [id=413] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 18:25:37.255+0000 [id=413] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 18:25:37.255+0000 [id=413] INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 12, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 18:25:37.256+0000 [id=413] INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 18:25:37.256+0000 [id=413] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 18:25:37.257+0000 [id=413] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 2 ms
18-19_absace_clairscanner_1 exited with code 0
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:02.959576","elapsed time":1195970,"method":"POST","remote addr":"172.18.0.6:39150","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:02.962853","elapsed time":878013,"method":"POST","remote addr":"172.18.0.6:39152","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:02.965722","elapsed time":912592,"method":"POST","remote addr":"172.18.0.6:39154","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:02.968795","elapsed time":1151629,"method":"POST","remote addr":"172.18.0.6:39156","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:02.971603","elapsed time":863307,"method":"POST","remote addr":"172.18.0.6:39158","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:02.974319","elapsed time":827064,"method":"POST","remote addr":"172.18.0.6:39160","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:02.978436","elapsed time":1158996,"method":"POST","remote addr":"172.18.0.6:39162","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:02.981213","elapsed time":845525,"method":"POST","remote addr":"172.18.0.6:39164","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:03.057613","elapsed time":74733668,"method":"POST","remote addr":"172.18.0.6:39166","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:03.070689","elapsed time":10632965,"method":"GET","remote addr":"172.18.0.6:39170","request uri":"/v1/layers/69f8e40013a3267a5ec92b2e3665d97fe6706e72e84bc074753a0d6c174d9801?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:03.084172","elapsed time":10095291,"method":"GET","remote addr":"172.18.0.6:39170","request uri":"/v1/layers/21e9982ef9d15e421de49108be3ba075f6c300a991c9b7633113c7b1b5585c21?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:03.097604","elapsed time":10091303,"method":"GET","remote addr":"172.18.0.6:39170","request uri":"/v1/layers/affa2b3d6ad019d130f99b310633f6b08fb46c1e2d71ac45e1f41b2a920a10ed?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:03.111134","elapsed time":10209168,"method":"GET","remote addr":"172.18.0.6:39170","request uri":"/v1/layers/fc5cbd861ba1bdefd682f3821c0424935483e3013e1e581d02d975b752a19aea?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:03.121527","elapsed time":6816254,"method":"GET","remote addr":"172.18.0.6:39170","request uri":"/v1/layers/a6175e7e36da80235b11eb57b283c18d48db28e9e9656354fe9e18e42263a67f?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:03.130130","elapsed time":6417332,"method":"GET","remote addr":"172.18.0.6:39170","request uri":"/v1/layers/6aca162c2dcdf2c2dc6a3983b4584e9b09802ff8f6530e733f828438c3827ae9?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:03.139063","elapsed time":6993742,"method":"GET","remote addr":"172.18.0.6:39170","request uri":"/v1/layers/55554b21af5ae92da6b70a0767ea4e58ba9e5a14e159858f107103218966000c?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:03.147436","elapsed time":6371770,"method":"GET","remote addr":"172.18.0.6:39170","request uri":"/v1/layers/6344b42c1c8e3c1134fa2dfe0ae114199376a63f38bc41640d426cca90bcb26d?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:03.156199","elapsed time":6686272,"method":"GET","remote addr":"172.18.0.6:39170","request uri":"/v1/layers/08bf86d6624450c487db18071224c88003d970848fb8c5b2b07df27e3f6869b2?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:07.239889","elapsed time":10199175,"method":"GET","remote addr":"172.18.0.6:39176","request uri":"/v1/layers/69f8e40013a3267a5ec92b2e3665d97fe6706e72e84bc074753a0d6c174d9801?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:07.253334","elapsed time":9666093,"method":"GET","remote addr":"172.18.0.6:39176","request uri":"/v1/layers/21e9982ef9d15e421de49108be3ba075f6c300a991c9b7633113c7b1b5585c21?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:07.266292","elapsed time":9716910,"method":"GET","remote addr":"172.18.0.6:39176","request uri":"/v1/layers/affa2b3d6ad019d130f99b310633f6b08fb46c1e2d71ac45e1f41b2a920a10ed?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:07.278856","elapsed time":9337676,"method":"GET","remote addr":"172.18.0.6:39176","request uri":"/v1/layers/fc5cbd861ba1bdefd682f3821c0424935483e3013e1e581d02d975b752a19aea?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:07.288485","elapsed time":6465552,"method":"GET","remote addr":"172.18.0.6:39176","request uri":"/v1/layers/a6175e7e36da80235b11eb57b283c18d48db28e9e9656354fe9e18e42263a67f?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:07.296842","elapsed time":6370378,"method":"GET","remote addr":"172.18.0.6:39176","request uri":"/v1/layers/6aca162c2dcdf2c2dc6a3983b4584e9b09802ff8f6530e733f828438c3827ae9?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:07.305811","elapsed time":6645117,"method":"GET","remote addr":"172.18.0.6:39176","request uri":"/v1/layers/55554b21af5ae92da6b70a0767ea4e58ba9e5a14e159858f107103218966000c?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:07.314278","elapsed time":6570911,"method":"GET","remote addr":"172.18.0.6:39176","request uri":"/v1/layers/6344b42c1c8e3c1134fa2dfe0ae114199376a63f38bc41640d426cca90bcb26d?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:07.322303","elapsed time":6000682,"method":"GET","remote addr":"172.18.0.6:39176","request uri":"/v1/layers/08bf86d6624450c487db18071224c88003d970848fb8c5b2b07df27e3f6869b2?vulnerabilities","status":"200"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:12.246711","elapsed time":1663737,"method":"POST","remote addr":"172.18.0.4:52104","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:12.248857","elapsed time":854158,"method":"POST","remote addr":"172.18.0.4:52106","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:12.250720","elapsed time":843443,"method":"POST","remote addr":"172.18.0.4:52108","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:12.252978","elapsed time":1253141,"method":"POST","remote addr":"172.18.0.4:52110","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:12.255444","elapsed time":789342,"method":"POST","remote addr":"172.18.0.4:52112","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:12.257328","elapsed time":820429,"method":"POST","remote addr":"172.18.0.4:52114","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:12.259368","elapsed time":1138017,"method":"POST","remote addr":"172.18.0.4:52116","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:12.261566","elapsed time":875981,"method":"POST","remote addr":"172.18.0.4:52118","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:12.263257","elapsed time":792812,"method":"POST","remote addr":"172.18.0.4:52120","request uri":"/v1/layers","status":"201"}
clair_1         | {"Event":"Handled HTTP request","Level":"info","Location":"router.go:57","Time":"2020-08-13 18:26:12.273886","elapsed time":9747476,"method":"GET","remote addr":"172.18.0.4:52122","request uri":"/v1/layers/69f8e40013a3267a5ec92b2e3665d97fe6706e72e84bc074753a0d6c174d9801?vulnerabilities","status":"200"}
jenkins_1       | 2020-08-13 18:26:13.766+0000 [id=380] INFO    o.j.p.workflow.job.WorkflowRun#finish: WebGoat_Pipeline #36 completed: SUCCESS
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
jenkins_1       | 2020-08-13 18:30:37.254+0000 [id=436] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Started DockerContainerWatchdog Asynchronous Periodic Work
jenkins_1       | 2020-08-13 18:30:37.254+0000 [id=436] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog has been triggered
jenkins_1       | 2020-08-13 18:30:37.254+0000 [id=436] INFO    c.n.j.p.d.DockerContainerWatchdog$Statistics#writeStatisticsToLog: Watchdog Statistics: Number of overall executions: 13, Executions with processing timeout: 0, Containers removed gracefully: 0, Containers removed with force: 0, Containers removal failed: 0, Nodes removed successfully: 0, Nodes removal failed: 0, Container removal average duration (gracefully): 0 ms, Container removal average duration (force): 0 ms, Average overall runtime of watchdog: 0 ms, Average runtime of container retrieval: 0 ms
jenkins_1       | 2020-08-13 18:30:37.255+0000 [id=436] INFO    c.n.j.p.d.DockerContainerWatchdog#loadNodeMap: We currently have 0 nodes assigned to this Jenkins instance, which we will check
jenkins_1       | 2020-08-13 18:30:37.255+0000 [id=436] INFO    c.n.j.p.d.DockerContainerWatchdog#execute: Docker Container Watchdog check has been completed
jenkins_1       | 2020-08-13 18:30:37.255+0000 [id=436] INFO    hudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished DockerContainerWatchdog Asynchronous Periodic Work. 1 ms
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
18-19_absace_clairscanner_1 exited with code 0
sonarqube_1     | 2020.08.13 18:33:01 INFO  app[][o.s.a.SchedulerImpl] Stopping SonarQube
sonarqube_1     | 2020.08.13 18:33:01 INFO  ce[][o.s.p.ProcessEntryPoint] Gracefully stopping process
sonarqube_1     | 2020.08.13 18:33:01 INFO  ce[][o.s.ce.app.CeServer] Compute Engine is stopping...
sonarqube_1     | 2020.08.13 18:33:01 INFO  ce[][o.s.c.t.CeProcessingSchedulerImpl] Gracefully stopping workers...
sonarqube_1     | 2020.08.13 18:33:02 INFO  ce[][o.s.ce.app.CeServer] Compute Engine is stopped
sonarqube_1     | 2020.08.13 18:33:02 INFO  app[][o.s.a.SchedulerImpl] Process[ce] is stopped
sonarqube_1     | 2020.08.13 18:33:02 INFO  web[][o.s.p.ProcessEntryPoint] Gracefully stopping process
sonarqube_1     | 2020.08.13 18:33:02 INFO  web[][o.s.s.n.NotificationDaemon] Notification service stopped
18-19_absace_jenkins_1 exited with code 143
sonarqube_1     | 2020.08.13 18:33:02 INFO  web[][o.s.s.p.d.EmbeddedDatabase] Embedded database stopped
sonarqube_1     | 2020.08.13 18:33:02 INFO  web[][o.s.s.app.WebServer] WebServer stopped
sonarqube_1     | 2020.08.13 18:33:02 INFO  app[][o.s.a.SchedulerImpl] Process[web] is stopped
sonarqube_1     | 2020.08.13 18:33:02 INFO  app[][o.s.a.SchedulerImpl] Process[es] is stopped
sonarqube_1     | 2020.08.13 18:33:02 WARN  app[][o.s.a.p.AbstractManagedProcess] Process exited with exit value [es]: 143
sonarqube_1     | 2020.08.13 18:33:02 INFO  app[][o.s.a.SchedulerImpl] SonarQube is stopped
18-19_absace_sonarqube_1 exited with code 143
18-19_absace_clairctl_1 exited with code 137
clair_1         | {"Event":"Received interruption, gracefully stopping ...","Level":"info","Location":"main.go:116","Time":"2020-08-13 18:33:12.182389"}
clair_1         | {"Event":"main API stopped","Level":"info","Location":"api.go:74","Time":"2020-08-13 18:33:12.182526"}
clair_1         | {"Event":"updater service stopped","Level":"info","Location":"updater.go:161","Time":"2020-08-13 18:33:12.182524"}
clair_1         | {"Event":"health API stopped","Level":"info","Location":"api.go:98","Time":"2020-08-13 18:33:12.182587"}
18-19_absace_clair_1 exited with code 0
postgres_1      | LOG:  received smart shutdown request
postgres_1      | LOG:  autovacuum launcher shutting down
postgres_1      | LOG:  shutting down
postgres_1      | LOG:  database system is shut down
18-19_absace_postgres_1 exited with code 0
ubuntu@ip-172-31-41-31:~/18-19_absace$
